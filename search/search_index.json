{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Upskilling Journey","text":"<p>Welcome :) This site is my personal upskilling space, where I track my progress toward key backend, DevOps, and software engineering KPIs. Each section shows my current status and achievements as I work toward my goals.</p>"},{"location":"#progress-overview","title":"Progress Overview","text":"Topic Goal/Description Current Level Git &amp; GitHub Master version control &amp; collaboration Level 2 (Complete) Project Management Understand dev project workflows Level 1 (Complete) Communication &amp; Collaboration Improve team communication skills Level 1 Documentation Write and maintain clear docs Level 1 (Complete) Containers &amp; Orchestration Deploy/manage containers &amp; clusters Level 1 Linux Confident Linux user/admin Level 1 CI/CD Automate build, test, deploy Level 1 (Complete) Observability Monitor and troubleshoot systems Level 1 (Complete) Redundancy &amp; DR Ensure system reliability &amp; recovery Level 1 Networking Understand and troubleshoot networks Level 1 Code + Design Patterns Apply proven coding/design techniques Level 1 Databases Use and optimize modern databases Level 1 (Complete) System Design Architect scalable, robust systems Level 1 (Complete) Security Build and maintain secure systems Level 1 API Design and implement robust APIs Level 1 (Complete) Authentication &amp; Authorization Securely manage user access Level 1 (Complete) Testing Confidently test and validate software Level 1 (Complete)"},{"location":"topics/API-Design/","title":"API Design","text":"<p>Goal: Design and implement well-structured, documented, and maintainable REST APIs.</p> <p>Current Level: Level 1</p>"},{"location":"topics/API-Design/#level-1-rest-api-fundamentals","title":"Level 1: REST API Fundamentals","text":"<ul> <li>Competencies: RESTful Design, HTTP Methods, Status Codes, API Documentation</li> <li>Tools: OpenAPI/Swagger, Spring Boot, Validation, Postman/curl</li> <li>Checklist:</li> <li> Design RESTful API endpoints following HTTP standards</li> <li> Implement proper HTTP status codes and error handling</li> <li> Add comprehensive API documentation with OpenAPI/Swagger</li> <li> Implement request validation and response formatting</li> </ul>"},{"location":"topics/API-Design/#level-2-advanced-api-design","title":"Level 2: Advanced API Design","text":"<ul> <li>Competencies: API Versioning, Rate Limiting, Authentication, Caching</li> <li>Tools: API Gateway, JWT, Redis, API Versioning Strategies</li> <li>Checklist:</li> <li> Implement API versioning strategy (URL, Header, Content-Type)</li> <li> Add rate limiting and throttling to API endpoints</li> <li> Implement JWT-based authentication for API security</li> <li> Add caching strategies for improved performance</li> </ul>"},{"location":"topics/API-Design/#level-3-api-architecture-governance","title":"Level 3: API Architecture &amp; Governance","text":"<ul> <li>Competencies: Microservices APIs, API Gateway, Service Mesh, API Governance</li> <li>Tools: Kong, Istio, API Management Platforms, GraphQL</li> <li>Checklist:</li> <li> Design APIs for microservices architecture</li> <li> Implement API Gateway with routing and load balancing</li> <li> Set up API governance and monitoring</li> <li> Design GraphQL APIs for flexible data querying</li> </ul>"},{"location":"topics/API-Design/#level-4-api-security-performance","title":"Level 4: API Security &amp; Performance","text":"<ul> <li>Competencies: OAuth2, API Security, Performance Optimization, Load Testing</li> <li>Tools: OAuth2, JWT, API Security Tools, Load Testing Tools</li> <li>Checklist:</li> <li> Implement OAuth2 and advanced authentication</li> <li> Add comprehensive API security measures</li> <li> Optimize API performance and response times</li> <li> Conduct load testing and performance analysis</li> </ul>"},{"location":"topics/API-Design/#level-5-api-strategy-leadership","title":"Level 5: API Strategy &amp; Leadership","text":"<ul> <li>Competencies: API Strategy, Developer Experience, API Monetization, Team Leadership</li> <li>Tools: API Management Platforms, Developer Portals, Analytics</li> <li>Checklist:</li> <li> Develop comprehensive API strategy and roadmap</li> <li> Create exceptional developer experience and documentation</li> <li> Implement API monetization and business models</li> <li> Lead API development teams and establish best practices</li> </ul>"},{"location":"topics/API-Design/#resources","title":"Resources","text":"<ul> <li>SpringDoc OpenAPI Documentation</li> <li>OpenAPI 3.0 Specification</li> <li>Spring Boot Validation Documentation</li> <li>REST API Best Practices</li> <li>Jakarta Bean Validation</li> <li>ChatGPT for code examples and troubleshooting</li> </ul>"},{"location":"topics/API-Design/#progress","title":"Progress","text":"Level 1: REST API Fundamentals <p>Status: Completed Focus: RESTful Design, HTTP Methods, Status Codes, API Documentation Tools Used: OpenAPI/Swagger, Spring Boot, Bean Validation Evidence: - Smart Deploy Monitor API - API Testing Results (Completed 18-10-2025): All 11/11 API design tests passing (100% success rate) - Swagger UI Integration (Completed 18-10-2025): Interactive API documentation at <code>/swagger-ui/index.html</code> - OpenAPI JSON (Completed 18-10-2025): Complete API specification at <code>/v3/api-docs</code></p> <p>What I Learned: - OpenAPI/Swagger Integration: Added comprehensive API documentation with SpringDoc OpenAPI - RESTful Design: Implemented proper HTTP methods (GET, POST, PUT, DELETE) with correct status codes - Request Validation: Added Bean Validation annotations (@NotBlank, @Email, @Size) for input validation - API Documentation: Created detailed OpenAPI annotations with examples, descriptions, and response schemas - Error Handling: Implemented proper HTTP status codes (200, 201, 400, 404, 500) for different scenarios - Response Formatting: Ensured consistent JSON response structure across all endpoints - API Testing: Created comprehensive testing suite for API design principles</p> <p>Resources Used: - SpringDoc OpenAPI documentation - Spring Boot validation documentation - OpenAPI 3.0 specification - REST API best practices guides - ChatGPT for code examples and troubleshooting</p> <p>Applied Knowledge: - Enhanced existing UserController with comprehensive OpenAPI documentation - Added request validation using Jakarta Bean Validation - Implemented proper HTTP status codes and error handling - Created detailed API documentation with examples and schemas - Built comprehensive testing suite to validate API design principles - Integrated Swagger UI for interactive API documentation - Ensured RESTful API design following industry standards</p> <p>All Level 1 tasks completed!</p> Level 2: Advanced API Design <p>Status: Planned Focus: API Versioning, Rate Limiting, Authentication, Caching</p> Level 3: API Architecture &amp; Governance <p>Status: Planned Focus: Microservices APIs, API Gateway, Service Mesh, API Governance</p> Level 4: API Security &amp; Performance <p>Status: Planned Focus: OAuth2, API Security, Performance Optimization, Load Testing</p> Level 5: API Strategy &amp; Leadership <p>Status: Planned Focus: API Strategy, Developer Experience, API Monetization, Team Leadership</p>"},{"location":"topics/API-Design/#evidence","title":"Evidence","text":"Level 1 Evidence <p>Repository: Smart Deploy Monitor API Demonstrations: - OpenAPI Configuration: Complete API documentation setup with SpringDoc - UserController Enhancement: Comprehensive API annotations and validation - API Testing Suite: Automated testing for all API design principles - Swagger UI Integration: Interactive API documentation interface</p> <p>API Endpoints: - <code>GET /api/users</code> - Retrieve all users with proper documentation - <code>POST /api/users</code> - Create user with validation and error handling - <code>GET /api/users/{id}</code> - Get user by ID with proper status codes - <code>PUT /api/users/{id}</code> - Update user with validation - <code>DELETE /api/users/{id}</code> - Delete user with proper error handling</p> <p>Testing Results: - \u2705 OpenAPI JSON documentation available - \u2705 Swagger UI accessible and functional - \u2705 API validation working (400 status for invalid requests) - \u2705 Consistent response format across all endpoints - \u2705 Proper HTTP status codes (200, 201, 400, 404, 500) - \u2705 RESTful API design following industry standards - \u2705 Error handling and status codes working correctly</p>"},{"location":"topics/API-Design/#personal-notes","title":"Personal Notes","text":"Note #1: API Design Implementation (18-10-2025) <p>To achieve Level 1: REST API Fundamentals, I implemented:</p> <p>1. OpenAPI/Swagger Integration <pre><code>@Configuration\npublic class OpenApiConfig {\n    @Bean\n    public OpenAPI smartDeployMonitorOpenAPI() {\n        return new OpenAPI()\n            .info(new Info()\n                .title(\"Smart Deploy Monitor API\")\n                .description(\"Comprehensive Spring Boot application...\")\n                .version(\"1.0.0\"));\n    }\n}\n</code></pre></p> <p>2. Request Validation <pre><code>@Schema(description = \"Request to create a new user\")\npublic static class CreateUserRequest {\n    @NotBlank(message = \"Email is required\")\n    @Email(message = \"Email must be valid\")\n    private String email;\n\n    @NotBlank(message = \"Password is required\")\n    @Size(min = 6, message = \"Password must be at least 6 characters\")\n    private String password;\n}\n</code></pre></p> <p>3. API Documentation <pre><code>@Operation(\n    summary = \"Create a new user\",\n    description = \"Creates a new user account with the provided information.\"\n)\n@ApiResponses(value = {\n    @ApiResponse(responseCode = \"201\", description = \"User created successfully\"),\n    @ApiResponse(responseCode = \"400\", description = \"Bad request - Invalid input\")\n})\n@PostMapping\npublic ResponseEntity&lt;Map&lt;String, Object&gt;&gt; createUser(@Valid @RequestBody CreateUserRequest request) {\n    // Implementation\n}\n</code></pre></p> <p>Key Learning: The combination of OpenAPI documentation, Bean Validation, and comprehensive testing creates a professional, maintainable API that follows industry standards.</p>"},{"location":"topics/API/","title":"API","text":"<p>Goal: Build robust and evolvable APIs using REST, GraphQL, and gRPC.</p> <p>Current Level: Level 1</p>"},{"location":"topics/API/#level-1-basic-rest-apis","title":"Level 1: Basic REST APIs","text":"<ul> <li>Competencies:</li> <li>Build basic REST APIs (CRUD)</li> <li>Understand HTTP methods and status codes</li> <li>Call APIs using Postman or curl</li> <li>Key Tools &amp; Practices:</li> <li>Express, Gin, Fastify, Postman, Swagger UI</li> <li>Basic routers and controllers</li> <li>Challenges to Master:</li> <li>Misusing status codes</li> <li>Forgetting to validate input</li> <li>Missing response formats</li> </ul>"},{"location":"topics/API/#level-2-rest-best-practices","title":"Level 2: REST Best Practices","text":"<ul> <li>Competencies:</li> <li>Apply REST principles (versioning, pagination, filtering)</li> <li>Write consistent endpoints</li> <li>Use OpenAPI or Swagger</li> <li>Key Tools &amp; Practices:</li> <li>Routing libraries</li> <li>OpenAPI/Swagger generators</li> <li>Request validation libraries</li> <li>Challenges to Master:</li> <li>Designing intuitive endpoints</li> <li>Managing breaking changes</li> <li>Handling validation consistently</li> </ul>"},{"location":"topics/API/#level-3-graphql-grpc","title":"Level 3: GraphQL &amp; gRPC","text":"<ul> <li>Competencies:</li> <li>Build GraphQL schemas and resolvers</li> <li>Use gRPC with Protobuf</li> <li>Understand streaming and schema evolution</li> <li>Key Tools &amp; Practices:</li> <li>Apollo Server, gqlgen, gRPC, Protobuf</li> <li>Code generation tools</li> <li>Challenges to Master:</li> <li>N+1 queries in GraphQL</li> <li>Versioning proto files</li> <li>Handling streaming clients</li> </ul>"},{"location":"topics/API/#level-4-api-security-gateway-integration","title":"Level 4: API Security &amp; Gateway Integration","text":"<ul> <li>Competencies:</li> <li>Secure APIs (JWT, OAuth2)</li> <li>Apply rate limiting and request throttling</li> <li>Integrate with API gateways</li> <li>Key Tools &amp; Practices:</li> <li>Keycloak, JWT libraries</li> <li>API Gateways (Kong, NGINX, Envoy)</li> <li>Rate limiter middlewares</li> <li>Challenges to Master:</li> <li>Token expiration &amp; refresh</li> <li>Enforcing scope-based access</li> <li>Detecting abuse patterns</li> </ul>"},{"location":"topics/API/#level-5-federated-evolvable-apis","title":"Level 5: Federated &amp; Evolvable APIs","text":"<ul> <li>Competencies:</li> <li>Federate APIs using GraphQL or gateways</li> <li>Manage multi-team APIs with clear ownership</li> <li>Design evolvable APIs</li> <li>Key Tools &amp; Practices:</li> <li>Apollo Federation</li> <li>gRPC Gateway</li> <li>Schema registry tools</li> <li>Challenges to Master:</li> <li>Coordinating breaking changes across teams</li> <li>Managing shared types and versioning</li> <li>Preventing over-fetching or under-fetching</li> </ul>"},{"location":"topics/API/#resources","title":"Resources","text":"<ul> <li>RESTful API Design</li> <li>GraphQL Docs</li> <li>gRPC Docs</li> <li>API Security Best Practices</li> </ul>"},{"location":"topics/API/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Basic REST APIs <p>Status: Planned Focus: Build basic REST APIs (CRUD), HTTP methods and status codes Tools: Express, Gin, Fastify, Postman, Swagger UI Next Task: Build first CRUD API with proper status codes</p> Level 2: REST Best Practices <p>Status: Planned Focus: REST principles (versioning, pagination, filtering) Tools: OpenAPI/Swagger generators, Request validation libraries</p> Level 3: GraphQL &amp; gRPC <p>Status: Planned Focus: GraphQL schemas and resolvers, gRPC with Protobuf</p> Level 4: API Security &amp; Gateway Integration <p>Status: Planned Focus: Secure APIs (JWT, OAuth2), rate limiting, API gateways</p> Level 5: Federated &amp; Evolvable APIs <p>Status: Planned Focus: Federate APIs, multi-team APIs, design evolvable APIs</p>"},{"location":"topics/API/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Auth/","title":"Authentication &amp; Authorization","text":"<p>Goal: Secure systems with robust, scalable, and standards-compliant authentication and authorization flows.</p> <p>Current Level: Level 1 (Complete)</p>"},{"location":"topics/Auth/#level-1-basic-auth","title":"Level 1: Basic Auth","text":"<ul> <li>Competencies:</li> <li>Understand authentication vs. authorization</li> <li>Manage Keycloak realms and clients</li> <li>Handle HTTP cookies and status codes</li> <li>Implement password hashing and session management</li> <li>Understand basic JWT concepts</li> <li>Key Tools &amp; Practices:</li> <li>Keycloak, HTTP/HTTPS protocols, Cookie management</li> <li>Checklist:</li> <li> Initialize Keycloak for web apps</li> <li> Configure and secure Keycloak</li> <li> Integrate multiple social logins</li> </ul>"},{"location":"topics/Auth/#level-2-intermediate-auth","title":"Level 2: Intermediate Auth","text":"<ul> <li>Competencies:</li> <li>Manage sessions with expiration and idle timeouts</li> <li>Implement \u201cRemember Me\u201d securely</li> <li>Enforce RBAC on protected routes</li> <li>Apply strict authorization</li> <li>Key Tools &amp; Practices:</li> <li>OPA, HttpOnly cookies, CSRF protection</li> <li>Checklist:</li> <li>Secure \u201cremember me\u201d with long-lived tokens</li> <li>Build admin-only sections</li> <li>Enforce CSRF protection via token validation</li> </ul>"},{"location":"topics/Auth/#level-3-advanced-auth","title":"Level 3: Advanced Auth","text":"<ul> <li>Competencies:</li> <li>Implement JWTs for stateless auth</li> <li>Handle token expiration, refresh flows, and secure storage</li> <li>Integrate OAuth2 and OpenID Connect</li> <li>Enforce authorization with scopes, roles, and attributes</li> <li>Key Tools &amp; Practices:</li> <li>JWT, Refresh Tokens, OAuth2, OIDC</li> <li>Checklist:</li> <li>Develop REST API to issue/verify JWTs</li> <li>Implement seamless token refresh</li> <li>Integrate OAuth2 providers (e.g., Google login)</li> </ul>"},{"location":"topics/Auth/#level-4-expert-auth","title":"Level 4: Expert Auth","text":"<ul> <li>Competencies:</li> <li>Design SSO for multi-app access</li> <li>Master OAuth2 grant types</li> <li>Link social logins with external identities</li> <li>Integrate enterprise protocols (SAML, OAuth/OIDC)</li> <li>Implement MFA and advanced authorization (group-based, ABAC)</li> <li>Key Tools &amp; Practices:</li> <li>Auth0, Keycloak, MFA, SSO, SAML</li> <li>Checklist:</li> <li>Set up and enforce MFA</li> <li>Optimize social login and identity linking</li> <li>Integrate and troubleshoot enterprise protocols</li> </ul>"},{"location":"topics/Auth/#level-5-master-auth","title":"Level 5: Master Auth","text":"<ul> <li>Competencies:</li> <li>Architect advanced auth (passwordless, WebAuthn)</li> <li>Follow OWASP best practices</li> <li>Design zero-trust microservice authorization</li> <li>Enable audit logging and proactive monitoring</li> <li>Guide adoption of evolving auth standards (OAuth 2.1, decentralized ID)</li> <li>Key Tools &amp; Practices:</li> <li>Magic Links, WebAuthn, Zero-Trust frameworks, OWASP, Audit Logging, Decentralized Identity</li> <li>Checklist:</li> <li>Validate and implement passwordless/biometric auth</li> <li>Establish robust logging and monitoring</li> <li>Mentor teams on secure coding and auth practices</li> </ul>"},{"location":"topics/Auth/#resources","title":"Resources","text":"<ul> <li>OAuth 2.0 Spec</li> <li>OpenID Connect</li> <li>OWASP Authentication Cheat Sheet</li> <li>Keycloak Docs</li> </ul>"},{"location":"topics/Auth/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: JWT Authentication &amp; Authorization (18-10-2025) <p>Status: Completed Focus: JWT authentication, OAuth2 integration, RBAC, security best practices Evidence: - Smart Deploy Monitor Authentication System - JWT Authentication (Completed 18-10-2025): Access and refresh token implementation with Spring Security - OAuth2 Integration (Completed 18-10-2025): Google and GitHub OAuth2 client configuration - Role-Based Access Control (Completed 18-10-2025): USER and ADMIN roles with endpoint protection - Security Configuration (Completed 18-10-2025): CORS, CSRF protection, and security headers - Keycloak Integration (Completed 18-10-2025): Enterprise identity management with Keycloak server - Dual Authentication System (Completed 18-10-2025): Both Spring Security + JWT and Keycloak authentication working - Keycloak Documentation Update (Completed 18-10-2025): Comprehensive documentation of Keycloak implementation and dual authentication architecture - Authentication Bug Fix (Completed 18-10-2025): Resolved double password encoding issue causing login failures</p> <p>What I Learned: - JWT Fundamentals: Token generation, validation, expiration, and refresh mechanisms - Spring Security: Authentication filters, security configuration, and user details service - OAuth2 Integration: External authentication providers and social login flows - RBAC Implementation: Role-based access control with method-level security - Security Best Practices: Password hashing, token storage, and secure communication - Authentication Flows: Registration, login, token refresh, and logout processes - Keycloak Integration: Enterprise identity management, realm configuration, and client setup - Dual Authentication: Implementing both custom JWT and enterprise Keycloak authentication - Docker Orchestration: Multi-service authentication with Docker Compose - Authentication Debugging: Identifying and resolving double password encoding issues in authentication flows</p> <p>Applied Knowledge: - Implemented JWT-based authentication with access and refresh tokens - Configured Spring Security with custom authentication filters - Integrated OAuth2 providers (Google, GitHub) for external authentication - Applied role-based access control to protect endpoints and resources - Implemented secure password hashing with BCrypt - Configured CORS and security headers for production deployment - Integrated Keycloak for enterprise identity management - Implemented dual authentication system (Spring Security + Keycloak) - Configured Docker Compose for multi-service authentication architecture - Debugged and resolved authentication issues with systematic problem-solving approach</p> <p>Authentication Architecture Examples: <pre><code>// JWT Service for token management\n@Service\npublic class JwtService {\n    public String generateToken(UserDetails userDetails) {\n        return Jwts.builder()\n            .setSubject(userDetails.getUsername())\n            .setIssuedAt(new Date())\n            .setExpiration(new Date(System.currentTimeMillis() + expiration))\n            .signWith(getSigningKey(), SignatureAlgorithm.HS256)\n            .compact();\n    }\n\n    public Boolean validateToken(String token, UserDetails userDetails) {\n        final String username = extractUsername(token);\n        return (username.equals(userDetails.getUsername()) &amp;&amp; !isTokenExpired(token));\n    }\n}\n\n// Security Configuration with RBAC\n@Configuration\n@EnableWebSecurity\npublic class SecurityConfig {\n    @Bean\n    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {\n        return http\n            .authorizeHttpRequests(auth -&gt; auth\n                .requestMatchers(\"/api/auth/**\").permitAll()\n                .requestMatchers(\"/api/users/**\").hasAnyRole(\"ADMIN\", \"USER\")\n                .requestMatchers(\"/api/database/**\").hasRole(\"ADMIN\")\n                .anyRequest().authenticated()\n            )\n            .addFilterBefore(jwtAuthenticationFilter, UsernamePasswordAuthenticationFilter.class)\n            .build();\n    }\n}\n\n// Keycloak Integration Configuration\n@KeycloakConfiguration\n@EnableMethodSecurity(prePostEnabled = true)\n@Import(KeycloakSpringBootConfigResolver.class)\npublic class KeycloakConfig extends KeycloakWebSecurityConfigurerAdapter {\n    @Autowired\n    public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception {\n        KeycloakAuthenticationProvider keycloakAuthenticationProvider = keycloakAuthenticationProvider();\n        keycloakAuthenticationProvider.setGrantedAuthoritiesMapper(new SimpleAuthorityMapper());\n        auth.authenticationProvider(keycloakAuthenticationProvider);\n    }\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        super.configure(http);\n        http\n            .csrf().disable()\n            .authorizeRequests()\n            .antMatchers(\"/keycloak/**\").permitAll()\n            .anyRequest().authenticated();\n    }\n}\n\n// Keycloak Controller for testing\n@RestController\n@RequestMapping(\"/keycloak\")\npublic class KeycloakController {\n    @GetMapping(\"/public\")\n    public ResponseEntity&lt;String&gt; publicEndpoint() {\n        return ResponseEntity.ok(\"Public endpoint accessible without Keycloak authentication.\");\n    }\n\n    @GetMapping(\"/secured\")\n    public ResponseEntity&lt;String&gt; securedEndpoint() {\n        return ResponseEntity.ok(\"Secured endpoint, accessible with Keycloak authentication.\");\n    }\n}\n</code></pre></p> <p>Authentication Endpoints Implemented: - <code>POST /api/auth/register</code> - User registration with validation - <code>POST /api/auth/login</code> - User authentication with JWT tokens - <code>POST /api/auth/refresh</code> - Token refresh mechanism - <code>POST /api/auth/logout</code> - User logout (client-side token removal) - <code>GET /keycloak/public</code> - Public endpoint accessible without Keycloak authentication - <code>GET /keycloak/secured</code> - Secured endpoint requiring Keycloak authentication - <code>GET /keycloak/admin</code> - Admin endpoint with role-based access control</p> <p>Security Features Implemented: - JWT access tokens with configurable expiration - Refresh tokens for seamless authentication - Role-based access control (USER, ADMIN) - OAuth2 integration for external providers - Password hashing with BCrypt - CORS configuration for cross-origin requests - Security headers and CSRF protection - Keycloak enterprise identity management - Dual authentication system (Spring Security + Keycloak) - Docker Compose multi-service architecture - Keycloak realm and client configuration</p> <p>Resources Used: - Spring Security documentation and best practices - JWT.io for token debugging and validation - OAuth2 specification and implementation guides - OWASP authentication security guidelines - Spring Boot security configuration patterns - Keycloak documentation and integration guides - Docker Compose multi-service orchestration - Enterprise authentication patterns </p> <p>Authentication Fix (Completed 18-10-2025): Resolved critical login endpoint issue where \"Bad credentials\" error occurred due to double password encoding during user registration. Fixed by removing redundant password encoding in AuthService.register() method, allowing UserService.createUser() to handle single encoding. This ensures proper password comparison during login authentication.</p> <p>Key Achievement: Successfully implemented a comprehensive authentication and authorization system with JWT tokens, OAuth2 integration, role-based access control, Keycloak enterprise identity management, dual authentication architecture, and resolved critical login authentication issues, demonstrating professional-level authentication system design and debugging skills.</p> Level 2: Session Management <p>Status: Planned Focus: Session management, RBAC implementation</p> Level 3: Modern Auth <p>Status: Planned Focus: JWT, OAuth2, scopes</p> Level 4: Enterprise Auth <p>Status: Planned Focus: SSO, OAuth2, MFA, protocols</p> Level 5: Advanced Security <p>Status: Planned Focus: Passwordless, WebAuthn, zero-trust, logging</p>"},{"location":"topics/Auth/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/CI-CD/","title":"CI/CD (Continuous Integration &amp; Deployment)","text":"<p>Goal: Build, test, and deploy software automatically using modern CI/CD tools and best practices.</p> <p>Current Level: Level 1</p>"},{"location":"topics/CI-CD/#level-1-cicd-fundamentals","title":"Level 1: CI/CD Fundamentals","text":"<ul> <li>Competencies: Basic GitHub Actions, YAML Pipelines, Continuous Integration</li> <li>Tools: GitHub Actions, YAML, Workflows, Runners</li> <li>Checklist:</li> <li> Set up a GitHub Actions workflow that runs on push</li> <li> Automate a simple build process using GitHub Actions</li> <li> Debug a failing CI/CD pipeline</li> </ul>"},{"location":"topics/CI-CD/#progress","title":"Progress","text":"<p>Completed: Smart Deploy Monitor CI/CD Pipeline</p> <p>What I Learned: - GitHub Actions: Created YAML workflows for automated testing and building - Maven Integration: Configured Maven builds in CI/CD pipeline with dependency caching - Java CI/CD: Set up Java 17 environment with proper build and test automation - Artifact Management: Uploaded build artifacts for deployment - Pipeline Debugging: Fixed workflow issues and optimized for monorepo structure - Conditional Triggers: Configured workflows to run only on specific directory changes</p> <p>Resources Used: - GitHub Actions documentation - Maven documentation - ChatGPT for troubleshooting pipeline issues - Spring Boot Maven plugin documentation</p> <p>How I Applied This Knowledge: - Created a complete CI/CD pipeline for the Spring Boot application - Implemented automated testing with Maven Surefire - Set up dependency caching to speed up builds - Configured proper Java environment setup - Added artifact upload for deployment readiness - Integrated with the observability application for end-to-end testing</p>"},{"location":"topics/CI-CD/#level-2-automated-testing-deployments","title":"Level 2: Automated Testing &amp; Deployments","text":"<ul> <li>Competencies: Unit Tests, Linting, Docker Builds, Secrets Management</li> <li>Tools: Docker, Jest/Pytest, GitHub Secrets, CodeCov, Linters</li> <li>Checklist:</li> <li> Integrate unit testing into CI/CD pipeline</li> <li> Set up Docker image builds and push to GHCR</li> <li> Configure secret management for sensitive credentials</li> </ul>"},{"location":"topics/CI-CD/#level-3-infrastructure-as-code-secure-deployments","title":"Level 3: Infrastructure as Code &amp; Secure Deployments","text":"<ul> <li>Competencies: Terraform, Kubernetes Deployments, GitOps</li> <li>Tools: Terraform, ArgoCD, Helm, Kubernetes</li> <li>Checklist:</li> <li> Automate infrastructure provisioning with Terraform</li> <li> Deploy a Kubernetes app using GitHub Actions</li> <li> Implement role-based access control (RBAC) for CI/CD workflows</li> </ul>"},{"location":"topics/CI-CD/#level-4-advanced-cicd-pipelines","title":"Level 4: Advanced CI/CD Pipelines","text":"<ul> <li>Competencies: Multi-Stage Builds, Observability, Deployment Rollbacks</li> <li>Tools: Prometheus, Grafana, Jaeger, Self-Hosted Runners, Canary Deployments</li> <li>Checklist:</li> <li> Implement multi-stage builds for optimized CI/CD pipelines</li> <li> Deploy a monitoring system for CI/CD health tracking</li> <li> Use self-hosted runners to speed up workflows</li> </ul>"},{"location":"topics/CI-CD/#level-5-enterprise-cicd-large-scale-infrastructure-automation","title":"Level 5: Enterprise CI/CD &amp; Large-Scale Infrastructure Automation","text":"<ul> <li>Competencies: Kubernetes Operators, Advanced GitOps, Full Automation</li> <li>Tools: GitHub Enterprise, Cross-Cluster Deployments, Spinnaker, Tekton</li> <li>Checklist:</li> <li> Design an enterprise-grade CI/CD pipeline for multiple teams</li> <li> Optimize a highly available self-hosted runner system</li> <li> Implement zero-downtime deployments at scale</li> </ul>"},{"location":"topics/CI-CD/#resources","title":"Resources","text":"<ul> <li>GitHub Actions Docs</li> <li>Terraform by HashiCorp</li> <li>ArgoCD Docs</li> <li>Tekton Pipelines</li> </ul>"},{"location":"topics/CI-CD/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: CI/CD Basics <p>Status: Planned Focus: Basics of CI/CD, GitHub Actions, YAML pipelines Next Task: Set up first GitHub Actions workflow</p> Level 2: Automated Testing &amp; Deployment <p>Status: Planned Focus: Automated testing, deployment pipelines</p> Level 3: Secure Pipelines <p>Status: Planned Focus: Secure CI/CD pipelines, Terraform (optional)</p> Level 4: Multi-Environment Pipelines <p>Status: Planned Focus: Multi-environment pipelines, self-hosted runners</p> Level 5: Enterprise CI/CD <p>Status: Planned Focus: Enterprise CI/CD, full infrastructure automation</p>"},{"location":"topics/CI-CD/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Code-Design-Patterns/","title":"Code + Design Patterns","text":"<p>Goal: Write clean, idiomatic, and performant code, and guide architecture decisions through patterns and standards.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Code-Design-Patterns/#level-1-core-programming-concurrency","title":"Level 1: Core Programming &amp; Concurrency","text":"<ul> <li>Competencies:</li> <li>Master language features and syntax</li> <li>Apply arrays, maps, trees, graphs, sorting/searching</li> <li>Write idiomatic, concurrent code</li> <li>Use goroutines, async/await, threads effectively</li> <li>Outcomes:</li> <li>Solve real-world problems using standard data structures</li> <li>Use built-in concurrency primitives</li> <li>Follow language idioms</li> <li>Challenges:</li> <li>Avoiding race conditions</li> <li>Mapping theory to practical problems</li> <li>Managing shared memory and goroutine/thread lifecycles</li> </ul>"},{"location":"topics/Code-Design-Patterns/#level-2-data-structures-code-organization","title":"Level 2: Data Structures &amp; Code Organization","text":"<ul> <li>Competencies:</li> <li>Use design patterns to solve recurring problems</li> <li>Write clean, modular, and scalable code</li> <li>Organize code by responsibility (feature/domain/layered)</li> <li>Outcomes:</li> <li>Apply SOLID principles</li> <li>Use separation of concerns</li> <li>Favor composition over inheritance</li> <li>Challenges:</li> <li>Avoiding over-abstracting</li> <li>Maintaining simplicity while scaling</li> <li>Teaching and enforcing architecture standards</li> </ul>"},{"location":"topics/Code-Design-Patterns/#level-3-advanced-algorithms-problem-solving","title":"Level 3: Advanced Algorithms &amp; Problem Solving","text":"<ul> <li>Competencies:</li> <li>Solve LeetCode Medium+ problems</li> <li>Use recursion, dynamic programming, greedy, backtracking</li> <li>Optimize space/time complexity under constraints</li> <li>Outcomes:</li> <li>Break down complex problems</li> <li>Write clear, performant solutions</li> <li>Communicate thought process effectively</li> <li>Challenges:</li> <li>Balancing readability with optimization</li> <li>Debugging under time pressure</li> <li>Recognizing algorithmic patterns</li> </ul>"},{"location":"topics/Code-Design-Patterns/#level-4-technical-leadership-codebase-stewardship","title":"Level 4: Technical Leadership &amp; Codebase Stewardship","text":"<ul> <li>Competencies:</li> <li>Lead complex refactors</li> <li>Mentor across code quality, design, and scalability</li> <li>Set code standards and enforce architecture discipline</li> <li>Outcomes:</li> <li>Provide effective reviews</li> <li>Advocate pattern reuse and clean abstractions</li> <li>Coach others on decision trade-offs</li> <li>Challenges:</li> <li>Balancing team autonomy with consistency</li> <li>Aligning tech direction with business goals</li> <li>Building team confidence through code mentoring</li> </ul>"},{"location":"topics/Code-Design-Patterns/#resources","title":"Resources","text":"<ul> <li>Design Patterns \u2013 Refactoring.Guru</li> <li>SOLID Principles</li> <li>LeetCode Practice</li> </ul>"},{"location":"topics/Code-Design-Patterns/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Core Programming <p>Status: Planned Focus: Language features, data structures, idiomatic code Next Task: Master basic data structures and concurrent programming</p> Level 2: Design Patterns <p>Status: Planned Focus: Design patterns, clean code, modularity</p> Level 3: Advanced Algorithms <p>Status: Planned Focus: Advanced problem solving, LeetCode Medium+</p> Level 4: Technical Leadership <p>Status: Planned Focus: Code quality reviews, long-term maintainability</p> Level 5: Architecture Leadership <p>Status: Planned Focus: Org-wide architecture and best practices</p>"},{"location":"topics/Code-Design-Patterns/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Communication-Collaboration/","title":"Communication &amp; Collaboration","text":"<p>Goal: Improve team communication and collaboration skills.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Communication-Collaboration/#level-1-communication-fundamentals","title":"Level 1: Communication Fundamentals","text":"<ul> <li>Competencies: Clear written communication, basic meeting etiquette, active listening</li> <li>Tools: Email, Slack, Teams, Google Meet</li> <li>Checklist:</li> <li> Write clear and concise emails/messages</li> <li> Participate in team meetings with basic etiquette</li> <li> Practice active listening in conversations</li> </ul>"},{"location":"topics/Communication-Collaboration/#level-2-team-collaboration","title":"Level 2: Team Collaboration","text":"<ul> <li>Competencies: Asynchronous updates, knowledge sharing, feedback culture</li> <li>Tools: Confluence, Google Docs, Standup bots</li> <li>Checklist:</li> <li> Share updates asynchronously with the team</li> <li> Contribute to shared documentation</li> <li> Give and receive constructive feedback</li> </ul>"},{"location":"topics/Communication-Collaboration/#level-3-conflict-resolution-facilitation","title":"Level 3: Conflict Resolution &amp; Facilitation","text":"<ul> <li>Competencies: Conflict resolution, facilitating meetings, inclusive communication</li> <li>Tools: Retrospective tools, Miro, Zoom breakout rooms</li> <li>Checklist:</li> <li> Help resolve a team conflict constructively</li> <li> Facilitate a team meeting or retrospective</li> <li> Ensure all voices are heard in discussions</li> </ul>"},{"location":"topics/Communication-Collaboration/#level-4-cross-team-collaboration","title":"Level 4: Cross-Team Collaboration","text":"<ul> <li>Competencies: Cross-team projects, stakeholder management, negotiation</li> <li>Tools: Jira, shared calendars, project management tools</li> <li>Checklist:</li> <li> Collaborate on a project with another team</li> <li> Manage stakeholder expectations</li> <li> Negotiate priorities or resources</li> </ul>"},{"location":"topics/Communication-Collaboration/#level-5-leadership-influence","title":"Level 5: Leadership &amp; Influence","text":"<ul> <li>Competencies: Mentoring, leading initiatives, organizational communication</li> <li>Tools: Mentoring platforms, company-wide forums, leadership training</li> <li>Checklist:</li> <li> Mentor or coach a team member</li> <li> Lead a cross-team initiative</li> <li> Communicate effectively at the organizational level</li> </ul>"},{"location":"topics/Communication-Collaboration/#resources","title":"Resources","text":"<ul> <li>Crucial Conversations Book</li> <li>Atlassian Team Playbook</li> <li>Google re:Work - Guide: Understand Team Effectiveness</li> </ul>"},{"location":"topics/Communication-Collaboration/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Basic Communication <p>Status: Planned Focus: Team communication, standups, async updates Next Task: Improve daily standup and documentation practices</p> Level 2: Effective Collaboration <p>Status: Planned Focus: Clear PRs, giving/receiving feedback, meeting etiquette</p> Level 3: Cross-Team Skills <p>Status: Planned Focus: Client collaboration, conflict resolution</p> Level 4: Knowledge Sharing <p>Status: Planned Focus: Mentorship, public speaking, documentation mastery</p> Level 5: Leadership Communication <p>Status: Planned Focus: Technical writing, developer advocacy</p>"},{"location":"topics/Communication-Collaboration/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Containers-Orchestration/","title":"Containers &amp; Orchestration","text":"<p>Goal: Master containerization with Docker and orchestrate scalable deployments using Kubernetes.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Containers-Orchestration/#level-1-docker-basics","title":"Level 1: Docker Basics","text":"<ul> <li>Competencies: Install, Pull, Run, Stop Containers, Volumes, Networks, Docker Compose</li> <li>Commands: Writing your first Dockerfile, <code>docker run</code>, <code>docker ps</code>, <code>docker stop</code>, <code>docker rm</code>, <code>docker volume</code>, <code>docker network</code>, <code>docker compose</code></li> <li>Checklist:</li> <li> Run a Docker container with a simple web app</li> <li> Bind a volume to a container to persist data</li> <li> Create a custom Docker network and connect two containers</li> </ul>"},{"location":"topics/Containers-Orchestration/#level-2-advanced-docker","title":"Level 2: Advanced Docker","text":"<ul> <li>Competencies: Multi-Container Apps, Storage, Container Registries</li> <li>Commands: <code>docker push</code>, <code>docker tag</code>, <code>docker build</code>, <code>docker inspect</code>, caching layer, multi-stage</li> <li>Checklist:</li> <li> Write a <code>docker-compose.yml</code> for a multi-container application</li> <li> Push an image to GHCR or Docker Hub</li> <li> Set up persistent storage using Docker volumes</li> </ul>"},{"location":"topics/Containers-Orchestration/#level-3-container-orchestration","title":"Level 3: Container Orchestration","text":"<ul> <li>Competencies: Kubernetes Basics, Docker Swarm, Helm</li> <li>Commands: <code>kubectl apply</code>, <code>kubectl get pods</code>, <code>kubectl logs</code>, Docker Swarm, <code>helm install</code></li> <li>Checklist:</li> <li> Deploy an application on Kubernetes using YAML files</li> <li> Use Helm charts to package and deploy an app</li> <li> Set up a basic Swarm cluster and deploy a service</li> </ul>"},{"location":"topics/Containers-Orchestration/#level-4-kubernetes-advanced","title":"Level 4: Kubernetes Advanced","text":"<ul> <li>Competencies: Scaling, Security, Monitoring, Service Mesh</li> <li>Commands: <code>kubectl scale</code>, <code>kubectl rollout</code>, <code>kubectl top</code>, <code>istioctl</code>, <code>linkerd</code>, <code>cilium</code></li> <li>Checklist:</li> <li> Implement Horizontal Pod Autoscaling (HPA)</li> <li> Deploy Kubernetes Network Policies</li> <li> Secure an app with Istio or Linkerd Service Mesh</li> </ul>"},{"location":"topics/Containers-Orchestration/#level-5-enterprise-kubernetes","title":"Level 5: Enterprise Kubernetes","text":"<ul> <li>Competencies: Multi-Cluster, Operators, Virtualization, Performance Tuning</li> <li>Commands: <code>kubeadm</code>, <code>kubevirt</code>, custom CRDs, <code>kubefed</code>, <code>cluster-api</code></li> <li>Checklist:</li> <li> Deploy a Multi-Cluster Kubernetes Federation</li> <li> Write a Custom Kubernetes Operator</li> <li> Optimize a large-scale Kubernetes cluster for 1000+ nodes</li> </ul>"},{"location":"topics/Containers-Orchestration/#resources","title":"Resources","text":"<ul> <li>Docker Docs</li> <li>Kubernetes Docs</li> <li>Awesome Kubernetes</li> </ul>"},{"location":"topics/Containers-Orchestration/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Docker Containerization (18-10-2025) <p>Status: Completed Focus: Multi-stage Docker builds, Docker Compose orchestration, container networking, volume persistence Evidence: - Smart Deploy Monitor Containerized Application - Multi-Stage Dockerfile (Completed 18-10-2025): Optimized Spring Boot container with security best practices - Docker Compose Orchestration (Completed 18-10-2025): Multi-service deployment with PostgreSQL, Redis, Elasticsearch, Qdrant - Container Networking (Completed 18-10-2025): Custom network with service discovery and health checks - Volume Persistence (Completed 18-10-2025): Data persistence for all database services</p> <p>What I Learned: - Docker Fundamentals: Container creation, multi-stage builds, image optimization - Docker Compose: Multi-service orchestration, service dependencies, health checks - Container Networking: Custom networks, service discovery, inter-container communication - Volume Management: Data persistence, volume mounting, backup strategies - Security Best Practices: Non-root users, minimal base images, security scanning - Production Readiness: Health checks, logging, monitoring, graceful shutdowns</p> <p>Applied Knowledge: - Created multi-stage Dockerfile for optimized Spring Boot application - Orchestrated 5 services (App, PostgreSQL, Redis, Elasticsearch, Qdrant) with Docker Compose - Implemented service discovery and health checks for all containers - Configured persistent volumes for database data - Applied security best practices with non-root user execution - Set up environment-based configuration for different deployment stages</p> <p>Container Architecture Examples: <pre><code># Multi-stage build for Spring Boot application\nFROM openjdk:17-jdk-slim as builder\nWORKDIR /app\nCOPY pom.xml .\nRUN ./mvnw dependency:go-offline -B\nCOPY src src\nRUN ./mvnw clean package -DskipTests\n\n# Production stage\nFROM openjdk:17-jre-slim\nWORKDIR /app\nRUN groupadd -r appuser &amp;&amp; useradd -r -g appuser appuser\nCOPY --from=builder /app/target/smart-deploy-monitor-1.0.0.jar app.jar\nRUN chown appuser:appuser app.jar\nUSER appuser\nEXPOSE 8080\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD curl -f http://localhost:8080/actuator/health || exit 1\nENTRYPOINT [\"java\", \"-jar\", \"app.jar\"]\n</code></pre></p> <p>Docker Compose Services: <pre><code>services:\n  postgres:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_DB: smart_deploy_monitor\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    networks:\n      - smart-deploy-network\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n\n  smart-deploy-monitor:\n    build: .\n    ports:\n      - \"8080:8080\"\n    environment:\n      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/smart_deploy_monitor\n    depends_on:\n      postgres:\n        condition: service_healthy\n    networks:\n      - smart-deploy-network\n</code></pre></p> <p>Container Operations Mastered: - <code>docker build</code> - Multi-stage image creation - <code>docker compose up -d</code> - Service orchestration - <code>docker ps</code> - Container monitoring - <code>docker logs</code> - Log analysis - <code>docker volume</code> - Data persistence - <code>docker network</code> - Service communication</p> <p>Resources Used: - Docker official documentation and best practices - Spring Boot containerization guidelines - Multi-service architecture patterns - Container security and optimization techniques - Production deployment strategies</p> <p>Key Achievement: Successfully containerized a complex Spring Boot application with 5 integrated services, implementing production-ready containerization with security, monitoring, and orchestration best practices.</p> Level 2: Advanced Docker <p>Status: Planned Focus: Multi-Container Apps, Storage, Container Registries Commands: <code>docker push</code>, <code>docker tag</code>, <code>docker build</code>, <code>docker inspect</code></p> Level 3: Container Orchestration <p>Status: Planned Focus: Kubernetes Basics, Docker Swarm, Helm Commands: <code>kubectl apply</code>, <code>kubectl get pods</code>, <code>kubectl logs</code></p> Level 4: Kubernetes Advanced <p>Status: Planned Focus: Scaling, Security, Monitoring, Service Mesh</p> Level 5: Enterprise Kubernetes <p>Status: Planned Focus: Multi-Cluster, Operators, Virtualization, Performance Tuning</p>"},{"location":"topics/Containers-Orchestration/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Databases/","title":"Databases","text":"<p>Goal: Design and operate performant, scalable databases.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Databases/#level-1-fundamentals","title":"Level 1: Fundamentals","text":"<ul> <li>Competencies: SQL basics, Redis commands, Elasticsearch DSL, Qdrant insert/query</li> <li>Tools: PostgreSQL, MS SQL, Oracle, Redis, Elasticsearch, Qdrant</li> <li>Checklist:</li> <li> Perform CRUD in SQL</li> <li> Search/filter with Elastic filters vs queries</li> <li> Insert/search vectors in Qdrant</li> <li> Use Redis for TTL-based caching</li> </ul>"},{"location":"topics/Databases/#level-2-schema-design","title":"Level 2: Schema Design","text":"<ul> <li>Competencies: Normalization, indexing, analyzers, Redis eviction, Qdrant collection config</li> <li>Tools: B-tree/GiST/GIN, EXPLAIN ANALYZE, Elastic mappings, Redis data types, Qdrant token filters</li> <li>Checklist:</li> <li> Normalize SQL tables and create optimal indexes</li> <li> Create analyzers in Elastic for multi-language support</li> <li> Tune Redis eviction policy</li> <li> Define Qdrant collection schema with metadata fields</li> </ul>"},{"location":"topics/Databases/#level-3-advanced-usage","title":"Level 3: Advanced Usage","text":"<ul> <li>Competencies: SQL functions, CTEs, triggers, Elastic aggregations/scripts, Redis rate limits, Qdrant optimization</li> <li>Tools: PL/pgSQL, T-SQL, Elastic Painless scripts, Redis Streams/Lua, Qdrant payload indexing</li> <li>Checklist:</li> <li> Use SQL functions and triggers to automate logic</li> <li> Aggregate and bucket results in Elastic</li> <li> Implement Redis-based rate limiting</li> <li> Optimize Qdrant collection with multiple segments and query filters</li> </ul>"},{"location":"topics/Databases/#level-4-operational-architecture","title":"Level 4: Operational Architecture","text":"<ul> <li>Competencies: Replica design, shard tuning, cache patterns, Qdrant payloads</li> <li>Tools: PgBouncer, AlwaysOn Ags, Redis caching layers, Qdrant indexed payloads</li> <li>Checklist:</li> <li> Route SQL reads to replicas</li> <li> Tune Elastic shard counts and replicas</li> <li> Implement Redis caching for different workloads</li> <li> Filter and score with Qdrant payloads</li> </ul>"},{"location":"topics/Databases/#level-5-distributed-dbs","title":"Level 5: Distributed DBs","text":"<ul> <li>Competencies: Geo-distribution, failover, hybrid search, alerting</li> <li>Tools: CockroachDB, Cassandra, Redis Sentinel, Prometheus + Grafana, Elastic + Qdrant</li> <li>Checklist:</li> <li> Deploy CockroachDB for geo-distributed SQL</li> <li> Handle key eviction and latency in Redis cluster</li> <li> Implement hybrid search (vector + keyword)</li> <li> Set alerts on DB metrics and failover</li> </ul>"},{"location":"topics/Databases/#resources","title":"Resources","text":"<ul> <li>Spring Data JPA Documentation</li> <li>PostgreSQL Official Documentation</li> <li>Spring Boot Database Configuration</li> <li>BCrypt Password Encryption</li> <li>Docker Compose Documentation</li> <li>ChatGPT for code examples and troubleshooting</li> </ul> Level 1: Fundamentals <p>Status: Completed Focus: SQL basics, PostgreSQL, Spring Data JPA, Database Integration Tools Used: PostgreSQL, Spring Data JPA, Docker Compose, BCrypt Evidence: - Smart Deploy Monitor Database - Database Testing Results (Completed 18-10-2025): All 5/5 database tests passing (100% success rate) - User Management System (Completed 18-10-2025): Complete CRUD operations with secure password handling - Database Integration (Completed 18-10-2025): PostgreSQL fully operational with Spring Boot</p> <p>What I Learned: - Spring Data JPA: Object-relational mapping with JPA annotations and repositories - PostgreSQL Integration: Database setup, connection configuration, and schema management - Entity Design: Created User entity with UUID primary keys, audit fields, and relationships - Repository Pattern: Implemented UserRepository with custom query methods and Spring Data JPA - Service Layer: Built UserService with business logic, password encryption, and user management - REST API Development: Created comprehensive UserController with CRUD operations - Password Security: Implemented BCrypt password encryption for secure user authentication - Database Testing: Created automated testing scripts for database operations - Redis TTL-based Caching: Implemented Redis caching with Time To Live for performance optimization - Elasticsearch Search/Filter: Created search services with filters (exact matches) and queries (relevance scoring) - Qdrant Vector Operations: Implemented vector insert/search operations for similarity search - Multi-Database Integration: Successfully integrated PostgreSQL, Redis, Elasticsearch, and Qdrant</p> <p>Resources Used: - Spring Data JPA documentation - PostgreSQL official documentation - Spring Boot database configuration guides - BCrypt password encryption tutorials - ChatGPT for code examples and troubleshooting</p> <p>Applied Knowledge: - Integrated PostgreSQL database into existing Spring Boot application - Created complete user management system with secure password handling - Implemented comprehensive REST API for user operations - Added Docker Compose setup for easy database deployment - Created automated testing scripts for database functionality - Documented complete database setup and usage guide - Successfully tested all database operations with 100% test pass rate - Verified user creation, retrieval, statistics, and password verification - Confirmed admin and regular user roles working correctly - Database integration fully operational and production-ready - Implemented Redis TTL-based caching for performance optimization - Created Elasticsearch search/filter services with filters and queries - Built Qdrant vector operations for similarity search and metadata filtering - Integrated multiple database technologies in a single Spring Boot application - Created comprehensive Level 1 database testing suite covering all requirements</p> <p>All Level 1 tasks completed!</p> Level 2: Schema Design <p>Status: Planned Focus: Normalization, indexing, analyzers, Redis eviction, Qdrant collection config</p> Level 3: Performance &amp; Optimization <p>Status: Planned Focus: Query optimization, indexing strategies, connection pooling, caching</p> Level 4: Advanced Database Operations <p>Status: Planned Focus: Replication, sharding, backup strategies, monitoring</p> Level 5: Database Architecture &amp; Leadership <p>Status: Planned Focus: Database strategy, team leadership, enterprise database management</p>"},{"location":"topics/Databases/#evidence","title":"Evidence","text":"Level 1 Evidence <p>Repository: Smart Deploy Monitor Database Demonstrations: - PostgreSQL Integration: Complete database setup with Docker Compose - User Entity: JPA entity with UUID, audit fields, and relationships - Repository Pattern: Custom query methods and Spring Data JPA integration - Service Layer: Business logic with password encryption and user management - REST API: Complete CRUD operations with proper error handling</p> <p>Database Operations: -  User creation with secure password hashing -  User retrieval by ID, email, and custom queries -  User statistics and analytics -  Password verification and change functionality -  Admin and regular user role management -  Redis TTL-based caching operations -  Elasticsearch search and filter operations -  Qdrant vector insert and search operations</p> <p>Level 1 Comprehensive Testing Results: -  PostgreSQL CRUD Operations: Working -  Redis TTL-based Caching: Working -  Elasticsearch Search/Filter: Working -  Qdrant Vector Operations: Working - All Level 1 database fundamentals successfully demonstrated and tested - All Level 1 database operations are working correctly: - \u2022 SQL CRUD operations with PostgreSQL - \u2022 TTL-based caching with Redis - \u2022 Search/filter operations with Elasticsearch - \u2022 Vector insert/search operations with Qdrant</p> <p>Testing Results: -  All 4/4 database services passing (100% success rate) -  PostgreSQL: 0 users (ready for operations) -  Redis: 2 keys (caching working) -  Elasticsearch: 1 document (search working) -  Qdrant: 0 points (vector operations ready)</p>"},{"location":"topics/Databases/#personal-notes","title":"Personal Notes","text":"Note #1: Database Integration Implementation (18-10-2025) <p>To achieve Level 1: Fundamentals, I implemented:</p> <p>1. PostgreSQL Database Setup <pre><code>spring:\n  datasource:\n    url: jdbc:postgresql://localhost:5432/smart_deploy_monitor\n    username: postgres\n    password: Root@123\n    driver-class-name: org.postgresql.Driver\n</code></pre></p> <p>2. User Entity with JPA Annotations <pre><code>@Entity\n@Table(name = \"users\")\npublic class User {\n    @Id\n    @GeneratedValue(strategy = GenerationType.AUTO)\n    private UUID id;\n\n    @Column(name = \"email\", nullable = false, unique = true)\n    private String email;\n\n    @Enumerated(EnumType.STRING)\n    private UserRole role = UserRole.USER;\n}\n</code></pre></p> <p>3. Repository with Custom Queries <pre><code>@Repository\npublic interface UserRepository extends JpaRepository&lt;User, UUID&gt; {\n    Optional&lt;User&gt; findByEmail(String email);\n    List&lt;User&gt; findByIsActiveTrue();\n    @Query(\"SELECT u FROM User u WHERE u.createdAt &gt;= :startDate\")\n    List&lt;User&gt; findUsersCreatedInLastDays(@Param(\"startDate\") LocalDateTime startDate);\n}\n</code></pre></p> <p>Key Learning: The combination of Spring Data JPA, PostgreSQL, and proper entity design creates a robust, scalable database layer that integrates seamlessly with Spring Boot applications.</p> Note #2: Level 1 \u2013 Multi-Database Integration (18-10-2025) <p>To complete Level 1: Fundamentals, I implemented:</p> <p>1. Redis TTL-based Caching <pre><code>@Service\npublic class CacheService {\n    public void setWithTTL(String key, Object value, long ttlSeconds) {\n        redisTemplate.opsForValue().set(key, value, Duration.ofSeconds(ttlSeconds));\n    }\n}\n</code></pre></p> <p>2. Elasticsearch Search/Filter Operations <pre><code>public List&lt;Map&lt;String, Object&gt;&gt; searchUsersWithFilters(String email, Boolean isActive) {\n    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();\n    if (email != null) {\n        boolQuery.filter(QueryBuilders.termQuery(\"email.keyword\", email));\n    }\n    // Filters are cached and faster for exact matches\n}\n</code></pre></p> <p>3. Qdrant Vector Operations <pre><code>public boolean insertVector(String pointId, List&lt;Float&gt; vector, Map&lt;String, Object&gt; payload) {\n    PointStruct point = PointStruct.newBuilder()\n        .setId(PointId.newBuilder().setUuid(pointId).build())\n        .setVectors(Vectors.newBuilder().setVector(Vector.newBuilder().addAllData(vector).build()).build())\n        .putAllPayload(qdrantPayload)\n        .build();\n}\n</code></pre></p> <p>Key Learning: Multi-database integration requires understanding each technology's strengths: PostgreSQL for ACID transactions, Redis for fast caching, Elasticsearch for full-text search, and Qdrant for vector similarity search.</p> Level 1 Complete Integration Results (18-10-2025) <p>All Level 1 Database Services Successfully Integrated and Tested:</p>"},{"location":"topics/Databases/#postgresql-crud-operations","title":"PostgreSQL CRUD Operations","text":"<ul> <li>Database Connection: UP</li> <li>User Entity: JPA annotations with UUID primary keys</li> <li>Repository: Custom queries with Spring Data JPA</li> <li>REST API: 15+ endpoints for user management</li> <li>Statistics: 0 users (ready for operations)</li> </ul>"},{"location":"topics/Databases/#redis-ttl-based-caching","title":"Redis TTL-based Caching","text":"<ul> <li>Redis Connection: UP (version 7.4.6)</li> <li>TTL Operations: Time-based key expiration</li> <li>Cache Management: Statistics and monitoring</li> <li>Statistics: 2 keys in cache</li> </ul>"},{"location":"topics/Databases/#elasticsearch-searchfilter-operations","title":"Elasticsearch Search/Filter Operations","text":"<ul> <li>Elasticsearch Connection: UP (yellow status - normal for single-node)</li> <li>Index Management: Creation and document indexing</li> <li>Search Operations: Filter and query capabilities</li> <li>Statistics: 1 document indexed</li> </ul>"},{"location":"topics/Databases/#qdrant-vector-operations","title":"Qdrant Vector Operations","text":"<ul> <li>Qdrant Service: UP and operational</li> <li>Collection Management: Creation and configuration</li> <li>Vector Operations: Insert and similarity search</li> <li>Statistics: 0 points (ready for operations)</li> </ul>"},{"location":"topics/Databases/#comprehensive-test-results","title":"Comprehensive Test Results","text":"<pre><code>=== Level 1 Database Testing Results ===\nPostgreSQL CRUD Operations: Working\nRedis TTL-based Caching: Working\nElasticsearch Search/Filter: Working\nQdrant Vector Operations: Working\n\nLevel 1 Database Fundamentals: COMPLETE!\n</code></pre>"},{"location":"topics/Databases/#key-achievements","title":"Key Achievements","text":"<ul> <li>SQL CRUD Operations: PostgreSQL with Spring Data JPA</li> <li>TTL-based Caching: Redis for performance optimization</li> <li>Search/Filter Operations: Elasticsearch for full-text search</li> <li>Vector Operations: Qdrant for similarity search and AI/ML</li> </ul> <p>Key Achievement: Successfully integrated and tested all four database technologies in a single Spring Boot application, demonstrating comprehensive Level 1 database fundamentals.</p>"},{"location":"topics/Databases/#evidence_1","title":"Evidence","text":"Level 1 Database Integration Evidence <p>Status: Completed Focus: Multi-Database Integration, PostgreSQL, Redis, Elasticsearch, Qdrant Tools Used: PostgreSQL, Redis, Elasticsearch, Qdrant, Spring Boot, Docker  </p> Personal Notes - Multi-Database Architecture Benefits <p>Why Multi-Database Architecture Matters:</p> <p>Real-World Application Benefits:</p> <ol> <li>Performance Optimization</li> <li>PostgreSQL: Handles complex relational data with ACID compliance</li> <li>Redis: Provides sub-millisecond response times for frequently accessed data</li> <li>Elasticsearch: Enables lightning-fast full-text search across millions of records</li> <li> <p>Qdrant: Powers AI/ML applications with vector similarity search</p> </li> <li> <p>Scalability &amp; Reliability</p> </li> <li>Database Specialization: Each database excels at its specific use case</li> <li>Load Distribution: Prevents single points of failure</li> <li>Independent Scaling: Scale each database based on its specific workload</li> <li> <p>Fault Tolerance: If one database fails, others continue operating</p> </li> <li> <p>Modern Application Requirements</p> </li> <li>Real-time Caching: Redis eliminates database hits for hot data</li> <li>Search Functionality: Elasticsearch provides Google-like search capabilities</li> <li>AI Integration: Qdrant enables semantic search and recommendation systems</li> <li> <p>Data Consistency: PostgreSQL ensures transactional integrity</p> </li> <li> <p>Business Value</p> </li> <li>User Experience: Faster response times and better search results</li> <li>Cost Efficiency: Right tool for the right job reduces infrastructure costs</li> <li>Future-Proofing: Architecture supports AI/ML and advanced analytics</li> <li> <p>Competitive Advantage: Modern applications require modern database strategies</p> </li> <li> <p>Technical Learning Outcomes</p> </li> <li>Polyglot Persistence: Understanding when to use which database</li> <li>Integration Patterns: How to connect multiple databases in one application</li> <li>Performance Tuning: Optimizing each database for its specific workload</li> <li>DevOps Skills: Managing multiple database services with Docker</li> </ol> <p>Key Insight: Modern applications don't use just one database - they use the right database for each specific need. This multi-database approach is the industry standard for scalable, high-performance applications.</p> <p>Next Level Preparation: This foundation enables learning advanced topics like database sharding, read replicas, data pipelines, and microservices architecture.</p>"},{"location":"topics/Databases/#project-evidence","title":"Project Evidence","text":"<ul> <li>Smart Deploy Monitor Multi-Database Integration</li> <li>Comprehensive Testing Results (Completed 18-10-2025): All 4/4 database services working (100% success rate)</li> <li>Multi-Database Architecture (Completed 18-10-2025): PostgreSQL, Redis, Elasticsearch, Qdrant fully integrated</li> <li>Docker Services (Completed 18-10-2025): All database services running in Docker containers</li> </ul>"},{"location":"topics/Databases/#code-implementation-evidence","title":"Code Implementation Evidence","text":"<p>PostgreSQL Integration: - Entity Layer: Created <code>User.java</code> with JPA annotations and UUID primary keys - Repository Layer: Implemented <code>UserRepository.java</code> with custom queries using <code>@Query</code> annotations - Service Layer: Built <code>UserService.java</code> with business logic and password encryption - Controller Layer: Developed <code>UserController.java</code> with 15+ REST endpoints for user management</p> <p>Redis Caching Implementation: - Service Layer: Created <code>RedisService.java</code> with TTL-based caching methods - Configuration: Implemented <code>RedisConfig.java</code> for <code>RedisTemplate</code> bean configuration - Management: Added cache statistics and management endpoints - Testing: Successfully tested TTL expiration functionality</p> <p>Elasticsearch Search Implementation: - Service Layer: Created <code>ElasticsearchService.java</code> for search operations - Index Management: Implemented index creation and document indexing - Search Operations: Added search and filter functionality with proper query building - Integration: Connected with Spring Boot's <code>ElasticsearchOperations</code></p> <p>Qdrant Vector Operations: - Service Layer: Created <code>QdrantService.java</code> for vector operations - Collection Management: Implemented collection creation and configuration - Vector Operations: Added vector insertion and similarity search capabilities - API Integration: Connected with Qdrant REST API using <code>RestTemplate</code></p>"},{"location":"topics/Databases/#code-snippets-evidence","title":"Code Snippets Evidence","text":"<p>PostgreSQL Entity Implementation: <pre><code>@Entity\n@Table(name = \"users\")\npublic class User {\n    @Id\n    @GeneratedValue(strategy = GenerationType.UUID)\n    private UUID id;\n\n    @Column(nullable = false)\n    private String firstName;\n\n    @Column(nullable = false)\n    private String lastName;\n\n    @Column(unique = true, nullable = false)\n    private String email;\n\n    @Enumerated(EnumType.STRING)\n    private UserRole role = UserRole.USER;\n}\n</code></pre></p> <p>Redis Service Implementation: <pre><code>@Service\npublic class RedisService {\n    @Autowired\n    private RedisTemplate&lt;String, Object&gt; redisTemplate;\n\n    public boolean setWithTTL(String key, Object value, long ttlSeconds) {\n        redisTemplate.opsForValue().set(key, value, ttlSeconds, TimeUnit.SECONDS);\n        return true;\n    }\n\n    public Object get(String key) {\n        return redisTemplate.opsForValue().get(key);\n    }\n}\n</code></pre></p> <p>Elasticsearch Service Implementation: <pre><code>@Service\npublic class ElasticsearchService {\n    @Autowired\n    private ElasticsearchOperations elasticsearchOperations;\n\n    public boolean createIndex(String indexName) {\n        return elasticsearchOperations.indexOps(IndexCoordinates.of(indexName)).create();\n    }\n\n    public boolean indexDocument(String indexName, String id, Map&lt;String, Object&gt; document) {\n        IndexQuery indexQuery = new IndexQueryBuilder()\n                .withId(id)\n                .withObject(document)\n                .build();\n        String documentId = elasticsearchOperations.index(indexQuery, IndexCoordinates.of(indexName));\n        return documentId != null &amp;&amp; !documentId.isEmpty();\n    }\n}\n</code></pre></p> <p>Qdrant Vector Operations: <pre><code>@Service\npublic class QdrantService {\n    private final String QDRANT_URL = \"http://localhost:6333\";\n\n    @Autowired\n    private RestTemplate restTemplate;\n\n    public boolean createCollection(String collectionName) {\n        String url = QDRANT_URL + \"/collections/\" + collectionName;\n        Map&lt;String, Object&gt; request = new HashMap&lt;&gt;();\n        Map&lt;String, Object&gt; vectors = new HashMap&lt;&gt;();\n        vectors.put(\"size\", 4);\n        vectors.put(\"distance\", \"Cosine\");\n        request.put(\"vectors\", vectors);\n\n        restTemplate.put(url, request);\n        return true;\n    }\n}\n</code></pre></p>"},{"location":"topics/Databases/#docker-integration-evidence","title":"Docker Integration Evidence","text":"<p>Multi-Service Docker Setup: - Configuration: Created <code>docker-services.yml</code> with Redis, Elasticsearch, and Qdrant services - Health Checks: Implemented comprehensive health checks for all services - Service Management: Created <code>start-services.sh</code> and <code>stop-services.sh</code> scripts - Networking: Added proper networking and volume management for data persistence</p>"},{"location":"topics/Databases/#api-integration-evidence","title":"API Integration Evidence","text":"<p>REST API Endpoints: - User Management: <code>/api/users</code> - Complete CRUD operations for user management - Redis Operations: <code>/api/database/redis/*</code> - Caching operations and statistics - Elasticsearch Operations: <code>/api/database/search/*</code> - Search and filter operations - Qdrant Operations: <code>/api/database/vector/*</code> - Vector operations and collection management - Statistics: <code>/api/database/stats</code> - Combined database statistics and health monitoring</p> <p>API Documentation: - OpenAPI/Swagger: Added SpringDoc OpenAPI documentation with comprehensive endpoint descriptions - Request Validation: Implemented Jakarta Bean Validation for request validation - API Testing: Created comprehensive API testing procedures and documentation</p>"},{"location":"topics/Databases/#configuration-evidence","title":"Configuration Evidence","text":"<p>Application Configuration: - Multi-Database Setup: Updated <code>application.yml</code> with configurations for all four databases - Connection Settings: Added proper connection timeouts and pool configurations - Spring Profiles: Implemented environment-specific configurations for development and production</p> <p>Maven Dependencies: - Redis Integration: Added <code>spring-boot-starter-data-redis</code> for Redis operations - Elasticsearch Integration: Added <code>spring-boot-starter-data-elasticsearch</code> for search operations - Qdrant Integration: Added <code>io.qdrant:client</code> for vector operations - Dependency Management: Properly configured all dependency versions and compatibility</p>"},{"location":"topics/Databases/#documentation-evidence","title":"Documentation Evidence","text":"<p>Comprehensive Documentation: - Setup Guides: <code>DATABASE-SERVICES-GUIDE.md</code> - Complete setup and configuration guide - Testing Guides: <code>SERVICE-TESTING-GUIDE.md</code> - Comprehensive testing procedures - MkDocs Integration: Updated documentation with detailed learning progress and evidence - Personal Notes: Added collapsible notes explaining multi-database architecture benefits</p>"},{"location":"topics/Databases/#git-integration-evidence","title":"Git Integration Evidence","text":"<p>Version Control: - Commit History: All code changes committed with descriptive commit messages - Repository Structure: Organized code in proper Maven project structure - Code Organization: Maintained clean separation between different database integrations - Documentation: All learning progress and evidence properly documented and versioned</p>"},{"location":"topics/Deployment/","title":"\ud83d\ude80 GitHub Pages Deployment Guide using MkDocs","text":"<p>This guide walks you through: 1. Initial setup 2. Deploying to GitHub Pages 3. Updating content 4. Best practices</p>"},{"location":"topics/Deployment/#prerequisites","title":"\u2705 Prerequisites","text":"<ul> <li>Python \u2265 3.7 installed</li> <li>Git installed and configured</li> <li>A GitHub repository (public or GitHub Pro if private)</li> <li>MkDocs and Material theme installed</li> </ul> <p>Install requirements:</p> <pre><code>pip install mkdocs mkdocs-material\n</code></pre> <p>Optional plugins (recommended):</p> <pre><code>pip install mkdocs-git-revision-date-localized\n</code></pre>"},{"location":"topics/Deployment/#1-project-structure","title":"\ud83c\udfd7\ufe0f 1. Project Structure","text":"<p>Your repo structure should look like this:</p> <pre><code>Upskilling/\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 topics/\n\u2502   \u2502   \u251c\u2500\u2500 Git-GitHub.md\n\u2502   \u2502   \u251c\u2500\u2500 CI-CD.md\n\u251c\u2500\u2500 mkdocs.yml\n</code></pre>"},{"location":"topics/Deployment/#2-mkdocsyml-example","title":"\u2699\ufe0f 2. <code>mkdocs.yml</code> Example","text":"<pre><code>site_name: Upskilling Journey\nsite_description: My curated docs for backend, DevOps, system design &amp; beyond.\nsite_url: https://AliAlSubhi98.github.io/Upskilling/\nrepo_url: https://github.com/AliAlSubhi98/Upskilling\nrepo_name: GitHub\n\ntheme:\n  name: material\n  features:\n    - navigation.sections\n    - navigation.indexes\n    - content.code.copy\n    - content.action.edit\n    - search.highlight\n    - search.share\n  palette:\n    - scheme: default\n      primary: blue\n      accent: deep purple\n    - scheme: slate\n      primary: blue\n      accent: deep purple\n      toggle:\n        icon: material/weather-night\n        name: Switch to dark mode\n  icon:\n    repo: fontawesome/brands/github\n\nnav:\n  - Home: index.md\n  - Git &amp; GitHub: topics/Git-GitHub.md\n  - CI/CD: topics/CI-CD.md\n  - Deployment Guide: Deployment.md\n\nmarkdown_extensions:\n  - toc:\n      permalink: true\n  - admonition\n  - codehilite\n  - pymdownx.superfences\n\nplugins:\n  - search\n  # Optional if installed\n  # - git-revision-date-localized:\n  #     fallback_to_build_date: true\n</code></pre>"},{"location":"topics/Deployment/#3-initial-deployment-to-github-pages","title":"\ud83d\ude80 3. Initial Deployment to GitHub Pages","text":""},{"location":"topics/Deployment/#step-a-initialize-and-push-repo","title":"Step A: Initialize and Push Repo","text":"<pre><code>git init\ngit add .\ngit commit -m \"Initial commit\"\ngit remote add origin https://github.com/AliAlSubhi98/Upskilling.git\ngit push -u origin main\n</code></pre>"},{"location":"topics/Deployment/#step-b-build-the-site","title":"Step B: Build the Site","text":"<pre><code>mkdocs build\n</code></pre>"},{"location":"topics/Deployment/#step-c-deploy-to-github-pages","title":"Step C: Deploy to GitHub Pages","text":"<pre><code>mkdocs gh-deploy\n</code></pre> <p>You will be prompted for GitHub credentials. Use a personal access token (PAT) instead of password.</p>"},{"location":"topics/Deployment/#4-enable-github-pages-in-repository","title":"\ud83c\udf10 4. Enable GitHub Pages in Repository","text":"<p>Go to: <code>https://github.com/AliAlSubhi98/Upskilling/settings/pages</code></p> <ul> <li>Source: Select <code>gh-pages</code> branch</li> <li>Directory: <code>/ (root)</code></li> <li>Save \u2705</li> </ul>"},{"location":"topics/Deployment/#5-how-to-update-the-docs","title":"\u270f\ufe0f 5. How to Update the Docs","text":"<ol> <li>Edit or add Markdown files under <code>docs/</code></li> <li>Run:</li> </ol> <pre><code>mkdocs build\nmkdocs gh-deploy\n</code></pre> <ol> <li>Changes will appear live at the GitHub Pages URL.</li> </ol>"},{"location":"topics/Deployment/#optional-cleanup","title":"\ud83e\uddfc Optional Cleanup","text":"<pre><code>mkdocs build --clean\nmkdocs serve  # for local preview\n</code></pre>"},{"location":"topics/Deployment/#best-practices","title":"\ud83d\udee1\ufe0f Best Practices","text":"<ul> <li>Commit changes regularly</li> <li>Use clear folder structure (<code>docs/topics/...</code>)</li> <li>Don't push <code>site/</code></li> <li>Add <code>site/</code> to <code>.gitignore</code></li> <li>Store secrets in <code>.env</code> and ignore them</li> </ul>"},{"location":"topics/Deployment/#common-error-address-already-in-use","title":"\ud83d\udee0\ufe0f Common Error: Address Already in Use","text":"<p>If you get this error while running:</p> <pre><code>mkdocs serve\n</code></pre> <p>And it returns something like:</p> <pre><code>OSError: [Errno 48] Address already in use\n</code></pre> <p>This means another process is using the default port <code>8000</code>. You have two ways to solve this:</p>"},{"location":"topics/Deployment/#option-1-kill-the-process-using-the-port","title":"\u2705 Option 1: Kill the Process Using the Port","text":"<p>Run the following to find the process ID:</p> <pre><code>lsof -i :8000\n</code></pre> <p>Then kill it:</p> <pre><code>kill -9 &lt;PID&gt;\n</code></pre> <p>Replace <code>&lt;PID&gt;</code> with the actual Process ID from the output.</p> <p>Example:</p> <pre><code>kill -9 12345\n</code></pre>"},{"location":"topics/Deployment/#option-2-use-a-different-port","title":"\u2705 Option 2: Use a Different Port","text":"<p>If you don\u2019t want to kill the running process, simply use another port:</p> <pre><code>mkdocs serve -a 127.0.0.1:8001\n</code></pre> <p>This tells MkDocs to run locally on port <code>8001</code> instead.</p>"},{"location":"topics/Documentation/","title":"Documentation","text":"<p>Goal: Write and maintain clear, effective documentation.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Documentation/#level-1-documentation-basics","title":"Level 1: Documentation Basics","text":"<ul> <li>Competencies: Writing README files, basic Markdown, documenting code usage</li> <li>Tools: Markdown, GitHub README, Google Docs</li> <li>Checklist:</li> <li> Write a clear project README</li> <li> Document code usage and examples</li> <li> Use basic Markdown formatting</li> </ul>"},{"location":"topics/Documentation/#level-2-structured-docs-standards","title":"Level 2: Structured Docs &amp; Standards","text":"<ul> <li>Competencies: API docs, docstrings, templates, style guides</li> <li>Tools: Sphinx, JSDoc, OpenAPI/Swagger, Confluence</li> <li>Checklist:</li> <li> Add docstrings/comments to functions and classes</li> <li> Create API documentation using a standard tool</li> <li> Follow a documentation style guide</li> </ul>"},{"location":"topics/Documentation/#level-3-collaborative-living-docs","title":"Level 3: Collaborative &amp; Living Docs","text":"<ul> <li>Competencies: Collaborative editing, versioned docs, changelogs, diagrams</li> <li>Tools: Google Docs, Notion, Mermaid, PlantUML</li> <li>Checklist:</li> <li> Collaborate on docs with teammates</li> <li> Maintain a changelog for your project</li> <li> Add diagrams to explain architecture or flows</li> </ul>"},{"location":"topics/Documentation/#level-4-automation-publishing","title":"Level 4: Automation &amp; Publishing","text":"<ul> <li>Competencies: Automated doc generation, publishing, continuous documentation</li> <li>Tools: MkDocs, Read the Docs, GitHub Pages, CI/CD integration</li> <li>Checklist:</li> <li> Automate documentation builds and publishing</li> <li> Host docs online for easy access</li> <li> Integrate doc updates into CI/CD pipeline</li> </ul>"},{"location":"topics/Documentation/#level-5-documentation-as-a-product","title":"Level 5: Documentation as a Product","text":"<ul> <li>Competencies: User guides, onboarding, localization, feedback loops</li> <li>Tools: Helpdesk platforms, translation tools, analytics</li> <li>Checklist:</li> <li> Create user guides or onboarding docs</li> <li> Localize documentation for multiple languages</li> <li> Collect and act on user feedback for docs</li> </ul>"},{"location":"topics/Documentation/#resources","title":"Resources","text":"<ul> <li>Google Technical Writing Courses</li> <li>Di\u00e1taxis Documentation Framework</li> <li>Write the Docs Community</li> </ul>"},{"location":"topics/Documentation/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Documentation Basics (18-10-2025) <p>Status: Completed Focus: READMEs, basic technical writing, Markdown formatting Evidence: - Upskilling Documentation Site - Smart Deploy Monitor Project - Comprehensive README Files (Completed 18-10-2025): Created detailed README files for all projects - MkDocs Documentation (Completed 18-10-2025): Built complete documentation site with navigation - Markdown Proficiency (Completed 18-10-2025): Professional formatting and structure</p> <p>What I Learned: - README Best Practices: Clear project descriptions, setup instructions, usage examples - Markdown Mastery: Headers, lists, code blocks, tables, links, and formatting - Documentation Structure: Logical organization and navigation - Technical Writing: Clear, concise, and user-friendly documentation - MkDocs Integration: Static site generation and GitHub Pages deployment - Version Control: Documentation as code with Git integration</p> <p>Applied Knowledge: - Created comprehensive README files for all projects with setup and usage instructions - Built professional MkDocs documentation site with proper navigation - Implemented consistent documentation standards across all projects - Used advanced Markdown features for professional presentation - Integrated documentation with CI/CD for automated deployment</p> <p>Resources Used: - MkDocs documentation and Material theme - GitHub Pages for hosting - Markdown best practices and formatting - Technical writing principles</p> <p>Key Achievement: Successfully created and maintained comprehensive documentation for multiple projects, demonstrating professional documentation skills and technical writing proficiency.</p> Level 2: Structured Documentation <p>Status: Planned Focus: API docs, user guides, knowledge bases</p> Level 3: Advanced Documentation <p>Status: Planned Focus: Documentation as code, automated generation</p> Level 4: Documentation Systems <p>Status: Planned Focus: Team documentation standards, governance</p> Level 5: Documentation Leadership <p>Status: Planned Focus: Org-wide documentation strategy and culture</p>"},{"location":"topics/Documentation/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Git-GitHub/","title":"Git &amp; GitHub","text":"<p>Goal: Master version control and collaboration using Git and GitHub.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Git-GitHub/#level-1-git-basics","title":"Level 1: Git Basics","text":"<ul> <li>Competencies: Init, Clone, Add, Commit, Push, Pull, Branching</li> <li>Commands: <code>git init</code>, <code>git clone</code>, <code>git add</code>, <code>git commit</code>, <code>git push</code>, <code>git pull</code>, <code>.gitignore</code></li> <li>Checklist:<ul> <li> Create a new repo and push to GitHub</li> <li> Clone a repo and make your first commit</li> <li> Use .gitignore to exclude files</li> </ul> </li> </ul>"},{"location":"topics/Git-GitHub/#level-2-advanced-branching-merging","title":"Level 2: Advanced Branching &amp; Merging","text":"<ul> <li>Competencies: Fast-Forward Merges, Three-Way Merges, Rebasing, Merge Conflicts, PRs</li> <li>Commands: <code>git branch</code>, <code>git checkout -b</code>, <code>git rebase</code>, <code>git merge</code>, <code>git cherry-pick</code>, GitHub PRs</li> <li>Checklist:<ul> <li> Create feature branches and merge using both merge and rebase</li> <li> Resolve complex merge conflicts</li> <li> Use git cherry-pick to selectively move commits across branches</li> </ul> </li> </ul>"},{"location":"topics/Git-GitHub/#level-3-commit-history-recovery","title":"Level 3: Commit History &amp; Recovery","text":"<ul> <li>Competencies: Reflog, Reset, Revert, Bisect, Tagging</li> <li>Commands: <code>git reflog</code>, <code>git reset --hard</code>, <code>git revert</code>, <code>git bisect</code>, <code>git tag</code></li> <li>Checklist:<ul> <li> Recover lost commits using reflog</li> <li> Use git bisect to find a bug in commit history</li> <li> Reset changes safely without losing work</li> </ul> </li> </ul>"},{"location":"topics/Git-GitHub/#level-4-enterprise-gitops-security","title":"Level 4: Enterprise GitOps &amp; Security","text":"<ul> <li>Competencies: Protected Branches, Signed Commits, CI/CD, LFS, GitHub Actions</li> <li>Commands: <code>git commit -S</code>, <code>git lfs</code>, GitHub Actions, Protected Branch Policies</li> <li>Checklist:<ul> <li> Enforce signed commits for security</li> <li> Set up GitHub Actions for automated testing</li> <li> Implement branch protection rules to enforce workflow policies</li> </ul> </li> </ul>"},{"location":"topics/Git-GitHub/#level-5-deep-git-internals-large-scale-gitops","title":"Level 5: Deep Git Internals &amp; Large-Scale GitOps","text":"<ul> <li>Competencies: Custom Hooks, Packfiles, GitHub API, Large Repos</li> <li>Commands: <code>git fsck</code>, <code>git worktree</code>, <code>git gc</code>, <code>git filter-branch</code>, GitHub API</li> <li>Checklist:<ul> <li> Optimize a large repository using git gc and repack</li> <li> Write a custom Git hook for automated commit checks</li> <li> Use the GitHub GraphQL API to automate repo management</li> </ul> </li> </ul>"},{"location":"topics/Git-GitHub/#resources","title":"Resources","text":"<ul> <li>Pro Git Book</li> <li>GitHub Docs</li> <li>Atlassian Git Tutorials</li> <li>How to Use Git Cherry-Pick: With Practical Examples</li> </ul>"},{"location":"topics/Git-GitHub/#progress","title":"Progress","text":"Level 1: Git Basics <p>Status: Completed Focus: Init, Clone, Add, Commit, Push, Pull, Branching Commands Practiced: <code>git init</code>, <code>git clone</code>, <code>git add</code>, <code>git commit</code>, <code>git push</code>, <code>git pull</code>, <code>.gitignore</code> Evidence: - Commit History - Upskilling repo commits</p> Level 2: Branching &amp; Merging <p>Status: Completed Focus: Fast-Forward, Rebasing, Merge Conflicts, Cherry-Pick, PRs Evidence: - Feature Branching Walkthrough - Merge Conflict Resolution (Completed 27-07-2025): Successfully resolved complex conflicts across multiple file sections - Cherry-Pick Practice (Completed 04-08-2024): Successfully demonstrated selective commit application across branches</p> <p>What I Learned: - Feature branching with proper naming and workflow - Merge vs rebase strategies and when to use each - Complex conflict resolution by combining changes intelligently - Cherry-pick for selective commit application across branches</p> <p>Resources Used: ChatGPT (AI Assistant) for step-by-step guidance</p> <p>Applied Knowledge: Built Java projects (UserAuth, PaymentProcessor, NotificationService) and practiced real-world Git scenarios</p> <p>All Level 2 tasks completed!</p> Level 3: Commit History &amp; Recovery <p>Status: Planned Focus: <code>git reflog</code>, <code>git reset</code>, <code>git revert</code>, <code>git bisect</code></p> Level 4: GitOps &amp; Security <p>Status: Planned Focus: CI/CD, Signed Commits, LFS, Protected Branches</p> Level 5: Git Internals &amp; Automation <p>Status: Planned Focus: Hooks, Packfiles, GitHub API, Performance</p>"},{"location":"topics/Git-GitHub/#evidence","title":"Evidence","text":"Level 1 Evidence <p>Repository: Practice Projects Demonstrations: - <code>repo-creation-push</code> - Web project with Git workflow - <code>clone-and-commit</code> - Java HelloWorld with version control - <code>gitignore-basics</code> - File exclusion patterns</p> Level 2 Evidence <p>Repository: Practice Projects Demonstrations: - <code>branching-workflow</code> - Feature branch management - <code>merge-vs-rebase</code> - Different merge strategies - <code>cherry-pick-practice</code> - Selective commit application</p> <p>Visual Documentation:</p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"topics/Git-GitHub/#personal-notes","title":"Personal Notes","text":"Note #1: Level 2 \u2013 Branching &amp; Merging (26-07-2025) <p>To achieve Level 2: Branching &amp; Merging, I followed these steps:</p> <p>1. Create a feature branch <pre><code>git checkout -b feature/advanced-branching\n</code></pre></p> <p>2. Make changes and commit <pre><code>git add .\ngit commit -m \"Update Git-GitHub.md with Level 2 notes\"\n</code></pre></p> <p>3. Rebase onto <code>main</code> <pre><code># Switch to main\ngit checkout main\n\n# Pull the latest changes\ngit pull origin main\n\n# Switch back to your feature branch\ngit checkout feature/advanced-branching\n\n# Rebase onto latest main\ngit rebase main\n</code></pre></p> <p>4. Push the branch and create a Pull Request <pre><code>git push origin feature/advanced-branching\n</code></pre></p> <p>5. Merge Pull Request <pre><code>- Open your PR on GitHub\n- Click \"Merge pull request\"\n- Confirm with \"Confirm merge\"\n- Optionally click \"Delete branch\"\n</code></pre></p> Note #2: Level 2 \u2013 Merge Conflict Resolution (27-07-2025) <p>Exercise Overview: Practiced resolving complex merge conflicts across multiple file sections.</p> <p>Scenario Created: - Created conflicting changes in <code>practice-file.md</code> across multiple sections - Main branch: Production configuration (MySQL, enhanced features) - Feature branch: Development configuration (PostgreSQL, basic features)</p> <p>Resolution Process: <pre><code># 1. Attempt merge (creates conflict)\ngit merge main\n# Output: CONFLICT (add/add): Merge conflict in practice-file.md\n\n# 2. Examine conflict markers\n# &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD (current branch)\n# ======= (separator)\n# &gt;&gt;&gt;&gt;&gt;&gt;&gt; main (incoming branch)\n\n# 3. Resolve by combining best of both versions\n# - Combined introduction text\n# - Added both production and development configurations\n# - Merged feature lists\n# - Created comprehensive notes section\n\n# 4. Complete the merge\ngit add practice-file.md\ngit commit -m \"Resolve merge conflicts: combine dev and production features\"\n</code></pre></p> <p>Skills Practiced: <pre><code>- Understanding conflict markers\n- Strategic conflict resolution (combining vs. choosing)\n- Maintaining clean repository after practice\n- Professional merge commit messages\n</code></pre></p> <p>Key Learnings: <pre><code>- Complex conflicts can be resolved by combining both versions intelligently\n- Always clean up practice files to keep repository organized\n- Document the resolution strategy in commit messages\n</code></pre></p> Note #3: Level 2 \u2013 Cherry-Pick Practice (04-08-2025) <p>Exercise Overview: Successfully practiced selective commit application using git cherry-pick.</p> <p>Scenario Created: - Created feature branch with 3 different features:   - UserAuth.java (user authentication)   - PaymentProcessor.java (payment processing)   - NotificationService.java (notification service) - Each feature committed separately for selective picking</p> <p>Cherry-Pick Process: <pre><code># 1. Created feature branch with multiple commits\ngit checkout -b feature/user-authentication\n# Added UserAuth.java, PaymentProcessor.java, NotificationService.java\n\n# 2. Switched back to main branch\ngit checkout main\n\n# 3. Cherry-picked specific commits\ngit cherry-pick 12827b6  # Payment processing feature\ngit cherry-pick c1de365  # User authentication feature\ngit cherry-pick 75ecc57  # Notification service feature\n</code></pre></p> <p>Skills Practiced: <pre><code>- Understanding commit hashes and their purpose\n- Selective commit application across branches\n- Managing multiple features in separate commits\n- Verifying cherry-pick results\n</code></pre></p> <p>Key Learnings: <pre><code>- Cherry-pick creates new commit IDs while preserving changes\n- Useful for applying hotfixes or specific features to different branches\n- Maintains clean commit history by selecting only needed changes\n- Essential skill for advanced Git workflows and release management\n</code></pre></p>"},{"location":"topics/Linux/","title":"Linux","text":"<p>Goal: Gain proficiency in Linux command-line tools, server management, virtualization, and automation.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Linux/#level-1-linux-cli-basics","title":"Level 1: Linux CLI Basics","text":"<ul> <li>Competencies: Navigation, File Management, Permissions, Users &amp; Groups</li> <li>Commands: <code>cd</code>, <code>ls</code>, <code>cp</code>, <code>mv</code>, <code>rm</code>, <code>chmod</code>, <code>chown</code>, <code>pwd</code>, <code>touch</code>, <code>cat</code>, <code>nano</code>, <code>sudo</code>, <code>man</code></li> <li>Checklist:</li> <li> Navigate through directories and list files with different options</li> <li> Modify file permissions using chmod and chown</li> <li> Create and manage users with useradd and passwd</li> </ul>"},{"location":"topics/Linux/#level-2-package-management-basic-scripting","title":"Level 2: Package Management &amp; Basic Scripting","text":"<ul> <li>Competencies: Installing &amp; Managing Software, Basic Shell Scripting, WSL</li> <li>Commands: <code>apt</code>, <code>yum</code>, <code>dnf</code>, <code>pacman</code>, <code>yay</code>, bash scripting, WSL</li> <li>Checklist:</li> <li> Install and manage software using package managers</li> <li> Set up and configure WSL on Windows</li> <li> Write a basic Bash script for automating repetitive tasks</li> </ul>"},{"location":"topics/Linux/#level-3-process-management-networking","title":"Level 3: Process Management &amp; Networking","text":"<ul> <li>Competencies: System Performance, Networking, Server Management</li> <li>Commands: <code>top</code>, <code>htop</code>, <code>ps</code>, <code>kill</code>, <code>netstat</code>, <code>ifconfig</code>, <code>systemctl</code>, <code>journalctl</code>, <code>crontab</code></li> <li>Checklist:</li> <li> Monitor system performance using top/htop</li> <li> Kill or prioritize processes using nice/renice</li> <li> Set up and manage system services using systemctl</li> </ul>"},{"location":"topics/Linux/#level-4-virtualization-containerization-security","title":"Level 4: Virtualization, Containerization &amp; Security","text":"<ul> <li>Competencies: Docker, Firewall, SSH, System Hardening</li> <li>Commands: VirtualBox, KVM, Docker, SSH, <code>iptables</code>, <code>ufw</code>, <code>fail2ban</code></li> <li>Checklist:</li> <li> Deploy and manage virtual machines using KVM or VirtualBox</li> <li> Set up and secure an SSH server</li> <li> Configure firewall rules using iptables or ufw</li> </ul>"},{"location":"topics/Linux/#level-5-advanced-system-administration-automation","title":"Level 5: Advanced System Administration &amp; Automation","text":"<ul> <li>Competencies: Kernel Compilation, Infrastructure as Code, Large-Scale Automation</li> <li>Commands: <code>systemd</code>, Ansible, Terraform, CI/CD, Kubernetes, Custom Kernels</li> <li>Checklist:</li> <li> Compile and run a custom Linux kernel</li> <li> Automate server setup using Ansible or Terraform</li> <li> Optimize a large-scale Linux deployment</li> </ul>"},{"location":"topics/Linux/#resources","title":"Resources","text":"<ul> <li>Linux Journey</li> <li>The Linux Command Line Book</li> <li>DigitalOcean Tutorials</li> </ul>"},{"location":"topics/Linux/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: CLI Basics <p>Status: Planned Focus: Navigation, permissions, basic file operations Commands: <code>ls</code>, <code>cd</code>, <code>mkdir</code>, <code>chmod</code>, <code>chown</code>, <code>grep</code>, <code>find</code> Next Task: Master basic file system navigation and permissions</p> Level 2: System Administration <p>Status: Planned Focus: Package managers, shell scripting, system monitoring Commands: <code>apt</code>, <code>yum</code>, <code>systemctl</code>, <code>cron</code>, <code>top</code>, <code>htop</code></p> Level 3: Advanced Administration <p>Status: Planned Focus: Process management, server management, automation</p> Level 4: Virtualization &amp; Security <p>Status: Planned Focus: VMs, containers, security hardening</p> Level 5: Kernel &amp; Infrastructure <p>Status: Planned Focus: Kernel customization, infrastructure as code</p>"},{"location":"topics/Linux/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Networking/","title":"Networking","text":"<p>Goal: Understand and manage computer networks, from IP basics to secure multi-cloud architecture.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Networking/#level-1-fundamentals","title":"Level 1: Fundamentals","text":"<ul> <li>Competencies:</li> <li>Basic network concepts (IP addressing, subnets, ports)</li> <li>Understanding TCP/IP and OSI models</li> <li>Networking tools (ping, traceroute, nslookup)</li> <li>HTTP/HTTPS protocols and status codes</li> <li>Basic firewall concepts</li> <li>Tools: Wireshark, ping, traceroute, nslookup, netstat, cURL, control panel configs</li> <li>Checklist:</li> <li> Understanding subnet math and IP addressing schemes</li> <li> Distinguishing between different protocol behaviors</li> <li> Troubleshooting connectivity issues</li> <li> Learning networking terminology and concepts</li> <li> Configuring local development environments</li> </ul>"},{"location":"topics/Networking/#level-2-advanced-fundamentals","title":"Level 2: Advanced Fundamentals","text":"<ul> <li>Competencies:</li> <li>Network topologies and architecture</li> <li>DNS configuration and troubleshooting</li> <li>Load balancing (types and when to use)</li> <li>VPN technologies and use cases</li> <li>Proxy servers and reverse proxies</li> <li>Tools: NGINX, Bind, OpenVPN/IPSec, iptables/ufw, Postman/Insomnia</li> <li>Checklist:</li> <li> Debugging DNS propagation issues</li> <li> Balancing security with accessibility</li> <li> Managing certificate lifecycles</li> <li> Understanding different proxy configurations</li> <li> Implementing proper network segmentation</li> </ul>"},{"location":"topics/Networking/#level-3-intermediate","title":"Level 3: Intermediate","text":"<ul> <li>Competencies:</li> <li>Network security best practices</li> <li>Implementing TLS/SSL certificates</li> <li>API gateway configuration</li> <li>Software-defined networking (SDN) basics</li> <li>VPC/subnet design in cloud environments</li> <li>Tools: Terraform, Let's Encrypt/Certbot, Nagios, Zabbix, AWS VPC, Azure VNET</li> <li>Checklist:</li> <li> Designing for scale and resilience</li> <li> Managing overlapping IP address spaces</li> <li> Implementing consistent security across environments</li> <li> Troubleshooting intermittent network issues</li> <li> Handling cross-region communication efficiently</li> </ul>"},{"location":"topics/Networking/#level-4-advanced","title":"Level 4: Advanced","text":"<ul> <li>Competencies:</li> <li>Kubernetes network models and CNI plugins</li> <li>Service mesh architecture and implementation</li> <li>Container networking optimization</li> <li>Zero-trust network access principles</li> <li>Layer 7 traffic management</li> <li>Tools: Istio, Linkerd, Cilium, Calico, Envoy, NetworkPolicy, Telepresence, ksniff</li> <li>Checklist:</li> <li> Troubleshooting complex service connectivity issues</li> <li> Optimizing network performance at scale</li> <li> Managing network policies across clusters</li> <li> Implementing secure cross-service communication</li> <li> Debugging microservice network flow</li> </ul>"},{"location":"topics/Networking/#level-5-expert","title":"Level 5: Expert","text":"<ul> <li>Competencies:</li> <li>Multi-cluster/multi-cloud network architecture</li> <li>Network automation and programmability</li> <li>eBPF-based networking innovations</li> <li>Custom network protocol optimization</li> <li>Global traffic management</li> <li>Tools: Cilium, Hubble, custom eBPF, multi-cluster mesh, Network as Code, advanced analyzers</li> <li>Checklist:</li> <li> Designing truly portable network abstractions</li> <li> Implementing consistent policies across heterogeneous environments</li> <li> Balancing networking innovation with stability</li> <li> Optimizing cost and performance at global scale</li> <li> Designing for extreme resilience and security</li> </ul>"},{"location":"topics/Networking/#resources","title":"Resources","text":"<ul> <li>Linux Networking Guide</li> <li>AWS VPC Concepts</li> <li>Kubernetes Network Policies</li> </ul>"},{"location":"topics/Networking/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Network Fundamentals <p>Status: Planned Focus: OSI model, TCP/IP, subnets, HTTP, ping, traceroute Next Task: Master basic networking concepts and troubleshooting</p> Level 2: Network Services <p>Status: Planned Focus: DNS, load balancing, VPN, proxy</p> Level 3: Advanced Networking <p>Status: Planned Focus: SSL/TLS, API gateways, SDN, VPC/subnet</p> Level 4: Container Networking <p>Status: Planned Focus: K8s network models, service mesh, zero trust</p> Level 5: Enterprise Networking <p>Status: Planned Focus: Multi-cloud, custom protocols, global traffic management</p>"},{"location":"topics/Networking/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Observability/","title":"Observability","text":"<p>Goal: Gain complete visibility into system health using logs, metrics, and traces.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Observability/#level-1-monitoring-logging-basics","title":"Level 1: Monitoring &amp; Logging Basics","text":"<ul> <li>Competencies: Log Analysis, Metrics Collection, Understanding Alerts</li> <li>Tools: Log Files, Syslog, journalctl, top, htop</li> <li>Checklist:</li> <li> Collect logs from a running application using journalctl or tail -f</li> <li> Use htop or top to monitor real-time system performance</li> <li> Configure basic alerts for server uptime</li> </ul>"},{"location":"topics/Observability/#progress","title":"Progress","text":"<p>Completed: Smart Deploy Monitor Application with Advanced Observability</p> <p>What I Learned: - Spring Boot Actuator: Built-in monitoring endpoints for health checks, metrics, and application info - Micrometer: Java metrics library for collecting application metrics (Counters, Timers, Gauges) - Structured Logging: Implemented SLF4J with Logback for consistent log formatting - Custom Metrics: Created custom metrics for request counting, response times, and system monitoring - Prometheus Integration: Exposed metrics in Prometheus format for monitoring systems - Scheduled Monitoring: Used Spring's @Scheduled to collect system metrics every 30 seconds</p> <p>Resources Used: - Spring Boot Actuator documentation - Micrometer documentation - ChatGPT for code examples and troubleshooting - Maven for dependency management</p> <p>How I Applied This Knowledge: - Built a complete Spring Boot application with observability features - Implemented custom metrics collection using Micrometer - Created multiple monitoring endpoints for different types of system information - Added unit tests to ensure monitoring functionality works correctly - Integrated with CI/CD pipeline for automated testing and deployment</p>"},{"location":"topics/Observability/#level-2-advanced-logging-metrics-collection","title":"Level 2: Advanced Logging &amp; Metrics Collection","text":"<ul> <li>Competencies: Centralized Logging, Structured Logs, Metrics Dashboards</li> <li>Tools: ELK Stack (Elasticsearch, Logstash, Kibana), Prometheus, Fluentd</li> <li>Checklist:</li> <li> Set up an ELK Stack and aggregate logs from multiple sources</li> <li> Create a Prometheus-based metrics dashboard</li> <li> Implement structured logging with JSON</li> </ul>"},{"location":"topics/Observability/#level-3-distributed-tracing-centralized-monitoring","title":"Level 3: Distributed Tracing &amp; Centralized Monitoring","text":"<ul> <li>Competencies: OpenTelemetry, Jaeger, Log Aggregation, Alerting</li> <li>Tools: OpenTelemetry (Otel), Jaeger, Grafana, Loki</li> <li>Checklist:</li> <li> Integrate Jaeger for distributed tracing in a microservices system</li> <li> Set up Grafana with Loki for real-time log visualization</li> <li> Configure log aggregation across multiple services</li> </ul>"},{"location":"topics/Observability/#level-4-full-observability-stack-incident-response","title":"Level 4: Full Observability Stack &amp; Incident Response","text":"<ul> <li>Competencies: Service Health, Tracing Pipelines, SLA Monitoring</li> <li>Tools: PagerDuty, Sentry, OpenTracing, Prometheus Alerts, Thanos</li> <li>Checklist:</li> <li> Implement a full observability stack with tracing, logs, and metrics</li> <li> Configure alerts with Prometheus &amp; PagerDuty</li> <li> Handle a live incident and create a postmortem report</li> </ul>"},{"location":"topics/Observability/#level-5-enterprise-observability-ai-based-monitoring","title":"Level 5: Enterprise Observability &amp; AI-Based Monitoring","text":"<ul> <li>Competencies: Machine Learning for Anomaly Detection, Large-Scale Tracing, Automated Infrastructure Health</li> <li>Tools: AI-Based Anomaly Detection, Kubernetes Observability, Cortex, New Relic, Datadog</li> <li>Checklist:</li> <li> Automate log analysis using AI-based anomaly detection</li> <li> Deploy observability for a large-scale Kubernetes cluster</li> <li> Implement self-healing infrastructure monitoring</li> </ul>"},{"location":"topics/Observability/#resources","title":"Resources","text":"<ul> <li>Prometheus Docs</li> <li>Grafana Labs</li> <li>OpenTelemetry</li> <li>ELK Stack Guide</li> </ul>"},{"location":"topics/Observability/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Basic Observability <p>Status: Planned Focus: Logging, metrics, application monitoring Next Task: Set up basic logging and metrics collection</p> Level 2: Centralized Monitoring <p>Status: Planned Focus: Centralized logging, ELK stack, Prometheus</p> Level 3: Full Stack Observability <p>Status: Planned Focus: Full observability stack, OpenTelemetry, alerting</p> Level 4: Advanced Monitoring <p>Status: Planned Focus: AI-based monitoring, infrastructure health automation</p> Level 5: Enterprise Observability <p>Status: Planned Focus: Complete observability strategy across systems</p>"},{"location":"topics/Observability/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Project-Management/","title":"Project Management","text":"<p>Goal: Manage development tasks efficiently using modern project management and agile practices.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Project-Management/#level-1-fundamentals-of-task-management","title":"Level 1: Fundamentals of Task Management","text":"<ul> <li>Competencies: Task Breakdown, Prioritization, Time Tracking, Status Updates</li> <li>Tools: Jira, Trello, GitHub Issues, Kanban Boards, Eisenhower Matrix, Pomodoro</li> <li>Checklist:</li> <li> Break down a user story into smaller actionable tasks</li> <li> Use Eisenhower Matrix to prioritize urgent vs. important tasks</li> <li> Track time spent on development tasks</li> </ul>"},{"location":"topics/Project-Management/#progress","title":"Progress","text":"<p>Completed: Smart Deploy Monitor V2 Project Management Practice</p> <p>What I Learned: - Task Breakdown: Broke down a complex project into 5 manageable tasks with clear dependencies - Eisenhower Matrix: Categorized tasks by urgency and importance (Urgent/Important, Important/Not Urgent, etc.) - Story Points: Estimated tasks using story points (1-8 scale) for sprint planning - Time Tracking: Used Pomodoro technique (25-minute focused sessions) for productivity - GitHub Issues: Created issue templates for bugs and features with proper labeling - Sprint Planning: Planned a 2-week sprint with 17 story points capacity</p> <p>Resources Used: - GitHub Issues documentation - Pomodoro technique guides - Agile project management principles - ChatGPT for task breakdown examples</p> <p>How I Applied This Knowledge: - Created a complete project plan for Smart Deploy Monitor V2 - Implemented task tracking with status updates and time logging - Used Eisenhower Matrix to prioritize database setup over documentation - Set up GitHub Issues with proper templates and labels - Tracked daily progress with Pomodoro sessions - Planned realistic sprint capacity (20 points) with buffer - GitHub Issues Integration: Created 5 detailed issues with story points, labels, milestones, and dependencies - Issue Templates: Designed bug report and feature request templates - Project Organization: Set up labels for priority, story points, sprints, and technology areas</p>"},{"location":"topics/Project-Management/#level-2-sprint-planning-task-complexity","title":"Level 2: Sprint Planning &amp; Task Complexity","text":"<ul> <li>Competencies: Estimations, Task Assignment, Workload Balancing, Team Collaboration</li> <li>Tools: Sprint Planning, Story Points, Planning Poker, MoSCoW Prioritization</li> <li>Checklist:</li> <li> Estimate tasks using story points and Planning Poker</li> <li> Identify task complexity and break it down</li> <li> Balance task assignments across a team of developers</li> </ul>"},{"location":"topics/Project-Management/#level-3-risk-dependency-management","title":"Level 3: Risk &amp; Dependency Management","text":"<ul> <li>Competencies: Handling Blockers, Backlog Grooming, Agile Metrics</li> <li>Tools: Burndown Charts, Lead Time, Cycle Time, RAID Log</li> <li>Checklist:</li> <li> Identify and document task dependencies</li> <li> Handle a blocker that delays sprint completion</li> <li> Use Cycle Time and Lead Time to improve task efficiency</li> </ul>"},{"location":"topics/Project-Management/#level-4-scaling-agile-release-planning","title":"Level 4: Scaling Agile &amp; Release Planning","text":"<ul> <li>Competencies: CI/CD Pipelines, Deployment Planning, Cross-Team Collaboration</li> <li>Tools: Release Cycles, Feature Flags, Trunk-Based Development, Roadmaps</li> <li>Checklist:</li> <li> Plan a feature release with milestones</li> <li> Coordinate between backend, frontend, and QA teams</li> <li> Use feature flags for incremental releases</li> </ul>"},{"location":"topics/Project-Management/#level-5-engineering-leadership-strategic-planning","title":"Level 5: Engineering Leadership &amp; Strategic Planning","text":"<ul> <li>Competencies: Scaling Agile, Large-Scale Sprint Planning, Data-Driven Decision Making</li> <li>Tools: OKRs, DORA Metrics, SPACE Framework, Cumulative Flow Diagrams</li> <li>Checklist:</li> <li> Design a quarterly roadmap for an engineering team</li> <li> Optimize team workflow using DORA Metrics</li> <li> Define and improve developer experience metrics</li> </ul>"},{"location":"topics/Project-Management/#resources","title":"Resources","text":"<ul> <li>Jira Software Guide</li> <li>Agile Estimation Techniques</li> <li>DORA DevOps Metrics</li> </ul>"},{"location":"topics/Project-Management/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Basic Project Management <p>Status: Planned Focus: Task breakdown, prioritization, time tracking Next Task: Practice basic project planning and task estimation</p> Level 2: Agile Practices <p>Status: Planned Focus: Sprint planning, story points, team collaboration</p> Level 3: Advanced Planning <p>Status: Planned Focus: Risk management, dependency handling, backlog grooming</p> Level 4: Cross-Team Leadership <p>Status: Planned Focus: Cross-team collaboration, release planning</p> Level 5: Engineering Leadership <p>Status: Planned Focus: Large-scale planning, metrics-driven decisions</p>"},{"location":"topics/Project-Management/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Redundancy-DR/","title":"Redundancy &amp; Disaster Recovery","text":"<p>Goal: Build resilient systems with backup, high availability, and automated recovery strategies.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Redundancy-DR/#level-1-basic-backup","title":"Level 1: Basic Backup","text":"<ul> <li>Competencies: Minimum viable protection from data loss.</li> <li>Tools: <code>pg_dump</code>, cron jobs, rsync, simple S3 uploads, any backup tool</li> <li>Checklist:</li> <li> Perform basic backup using any tool</li> </ul>"},{"location":"topics/Redundancy-DR/#level-2-automated-backups-monitoring","title":"Level 2: Automated Backups &amp; Monitoring","text":"<ul> <li>Competencies: Improved reliability and observability.</li> <li>Tools: pgBackRest, barman, restic, Prometheus + Alertmanager</li> <li>Checklist:</li> <li> Scheduled, incremental backups (e.g., WAL archiving for PostgreSQL)</li> <li> Monitoring backup success/failure (alerts if missed)</li> <li> Backup encryption and retention policy</li> <li> Manual restore plan tested occasionally</li> </ul>"},{"location":"topics/Redundancy-DR/#level-3-ha-high-availability","title":"Level 3: HA (High Availability)","text":"<ul> <li>Competencies: Avoid downtime with minimal data loss (RPO, RTO ~ minutes)</li> <li>Tools: PostgreSQL replication, Patroni, HAProxy, etcd, Ansible</li> <li>Checklist:</li> <li> Hot standby or streaming replication</li> <li> Automated failover (e.g., Patroni, repmgr)</li> <li> Load balancer or service discovery for DB connection routing</li> <li> Configuration and infrastructure as code</li> </ul>"},{"location":"topics/Redundancy-DR/#level-4-geo-redundancy-dr-planning","title":"Level 4: Geo-Redundancy &amp; DR Planning","text":"<ul> <li>Competencies: Survive full region failures</li> <li>Tools: Logical replication, pglogical, Citus, DNS failover</li> <li>Checklist:</li> <li> Cross-region replication (async or cascaded)</li> <li> Automated DNS failover (Route53, Cloudflare, etc.)</li> <li> Regular DR drills (simulate failure + restore)</li> <li> RTO &amp; RPO defined and measured</li> <li> App layer aware of region failover</li> </ul>"},{"location":"topics/Redundancy-DR/#level-5-fully-automated-self-healing-multi-region-active-active","title":"Level 5: Fully Automated Self-Healing &amp; Multi-Region Active-Active","text":"<ul> <li>Competencies: Always-on, resilient, self-healing infrastructure</li> <li>Tools: Citus, Kubernetes, Vault, Service Mesh, GitOps, Terraform</li> <li>Checklist:</li> <li> Multi-region active-active setup (e.g., sharded or conflict-resolved)</li> <li> Infrastructure self-heals on failure (k8s, operators)</li> <li> Continuous backup + PITR (Point-in-Time Recovery)</li> <li> Infrastructure &amp; DB schema versioned (e.g., GitOps)</li> </ul>"},{"location":"topics/Redundancy-DR/#resources","title":"Resources","text":"<ul> <li>PostgreSQL High Availability Guide</li> <li>Disaster Recovery Planning by AWS</li> <li>Citus Multi-Node Docs</li> </ul>"},{"location":"topics/Redundancy-DR/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Basic Backup <p>Status: Planned Focus: Basic backup strategies and recovery procedures Next Task: Implement basic backup and recovery for a database</p> Level 2: Automated Backups <p>Status: Planned Focus: Automated backups and monitoring</p> Level 3: High Availability <p>Status: Planned Focus: HA system design and implementation</p> Level 4: Disaster Recovery <p>Status: Planned Focus: DR planning and testing</p> Level 5: Self-Healing Systems <p>Status: Planned Focus: Self-healing, multi-region active-active</p>"},{"location":"topics/Redundancy-DR/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Security/","title":"Security","text":"<p>Goal: Build secure systems with strong development and operational practices.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Security/#level-1-basic-security","title":"Level 1: Basic Security","text":"<ul> <li>Competencies: Understand and apply essential security practices to reduce obvious risks.</li> <li>Tools: Spring Security, BCrypt, HTTPS, Input Validation, Environment Variables</li> <li>Checklist:</li> <li> HTTPS enabled (with valid TLS cert)</li> <li> Input validation using Spring Boot validation annotations</li> <li> Secure password storage using BCrypt</li> <li> No secrets or credentials in code/repos</li> </ul>"},{"location":"topics/Security/#level-2-secure-development-practices","title":"Level 2: Secure Development Practices","text":"<ul> <li>Competencies: Develop with security in mind and address common OWASP risks.</li> <li>Tools: Spring Security, OWASP ZAP, Snyk, Dependabot, JWT, CORS</li> <li>Checklist:</li> <li> Protection against OWASP Top 10 (XSS, CSRF, SQLi, etc.)</li> <li> Role-based access control (RBAC) with Spring Security</li> <li> Rate limiting / brute-force protection</li> <li> Secrets management system in place (e.g., Vault or SSM)</li> <li> Dependency vulnerability scanning</li> </ul>"},{"location":"topics/Security/#level-3-app-layer-threat-modeling-secure-sdlc","title":"Level 3: App Layer Threat Modeling &amp; Secure SDLC","text":"<ul> <li>Competencies: Build software with security embedded in the design and lifecycle.</li> <li>Tools: Keycloak, OPA, Gosec, OWASP ZAP, GitHub Actions security scans</li> <li>Checklist:</li> <li> Threat modeling done per service (e.g., STRIDE, DFD)</li> <li> Security testing integrated in CI/CD (SAST, DAST)</li> <li> Centralized authentication/authorization (OAuth2, OIDC, Keycloak)</li> <li> Logging/auditing of sensitive operations</li> <li> Input/output encoding via secure libraries</li> </ul>"},{"location":"topics/Security/#level-4-continuous-security-monitoring","title":"Level 4: Continuous Security &amp; Monitoring","text":"<ul> <li>Competencies: Detect and respond to threats in real-time, minimize attack window.</li> <li>Tools: Loki/Grafana, Alertmanager, Cloudflare WAF, Falco, Prometheus, JWT/mTLS</li> <li>Checklist:</li> <li> Centralized log aggregation (e.g., ELK/Promtail)</li> <li> Real-time alerting on anomalies and abuse patterns</li> <li> Web Application Firewall (WAF) in place</li> <li> API security tokens with expiry, rotation (JWT, mTLS)</li> <li> Security incidents documented and practiced (playbooks)</li> </ul>"},{"location":"topics/Security/#level-5-zero-trust-offensive-readiness","title":"Level 5: Zero Trust + Offensive Readiness","text":"<ul> <li>Competencies: Architect systems assuming compromise; proactively test and defend.</li> <li>Tools: Istio, Tailscale, OPA/Rego, Casbin, Burp Suite, SecurityScorecard, GCP/AWS Identity-Aware Proxy</li> <li>Checklist:</li> <li> Zero Trust architecture (identity-aware proxies, least privilege)</li> <li> Bug bounty / red teaming / penetration testing pipeline</li> <li> Secrets rotation automation + Just-in-Time access for any sensitive systems</li> <li> AI/ML anomaly detection for usage &amp; traffic using security tools and monitoring tools</li> </ul>"},{"location":"topics/Security/#resources","title":"Resources","text":"<ul> <li>OWASP Top Ten</li> <li>Go Security Best Practices</li> <li>GitHub Security Features</li> </ul>"},{"location":"topics/Security/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Basic Security (18-10-2025) <p>Status: Completed Focus: Spring Security, authentication, input validation, secure password storage Evidence: - Smart Deploy Monitor Security Implementation - Spring Security Integration (Completed 18-10-2025): Implemented authentication and authorization - BCrypt Password Encryption (Completed 18-10-2025): Secure password storage with BCrypt - Input Validation (Completed 18-10-2025): Jakarta Bean Validation for request validation - Environment Security (Completed 18-10-2025): No secrets in code, proper configuration management</p> <p>What I Learned: - Spring Security: Authentication and authorization framework for Spring Boot applications - BCrypt Password Hashing: Secure password storage with salt and hashing - Input Validation: Jakarta Bean Validation annotations for request validation - Security Configuration: Proper security configuration and best practices - Environment Variables: Secure configuration management without hardcoded secrets - HTTPS Configuration: SSL/TLS configuration for secure communication</p> <p>Applied Knowledge: - Implemented BCryptPasswordEncoder for secure password storage - Added input validation using @Valid, @NotBlank, @Email annotations - Configured Spring Security for authentication and authorization - Used environment variables for sensitive configuration - Implemented proper error handling for security-related issues - Applied security best practices throughout the application</p> <p>Code Examples: <pre><code>@Configuration\npublic class SecurityConfig {\n    @Bean\n    public BCryptPasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n}\n\n@RestController\npublic class UserController {\n    @PostMapping(\"/api/users\")\n    public ResponseEntity&lt;?&gt; createUser(@Valid @RequestBody UserDTO userDTO) {\n        // Input validation automatically applied\n        String hashedPassword = passwordEncoder.encode(userDTO.getPassword());\n        // Secure password storage\n    }\n}\n</code></pre></p> <p>Resources Used: - Spring Security documentation and best practices - BCrypt password hashing implementation - Jakarta Bean Validation for input validation - Spring Boot security configuration - OWASP security guidelines</p> <p>Key Achievement: Successfully implemented comprehensive security measures in Spring Boot application including authentication, authorization, secure password storage, and input validation, demonstrating professional security practices.</p> Level 2: Secure Development <p>Status: Planned Focus: Secure coding practices, dependency scanning</p> Level 3: Application Security <p>Status: Planned Focus: Threat modeling, secure SDLC</p> Level 4: Security Operations <p>Status: Planned Focus: Continuous security monitoring, incident response</p> Level 5: Advanced Security <p>Status: Planned Focus: Zero trust architecture, offensive security readiness</p>"},{"location":"topics/Security/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/System-Design/","title":"System Design","text":"<p>Goal: Master the design of scalable, reliable, and maintainable systems.</p> <p>Current Level: Level 1</p>"},{"location":"topics/System-Design/#level-1-system-design-fundamentals","title":"Level 1: System Design Fundamentals","text":"<ul> <li>Competencies:</li> <li>Client-server architecture</li> <li>Monolith vs microservices</li> <li>Basic API design</li> <li>Load balancing</li> <li>Caching</li> <li>Database selection</li> <li>Key Tools &amp; Practices:</li> <li>API documentation tools (Swagger, OpenAPI)</li> <li>Infrastructure diagrams</li> <li>HTTP clients (Postman, cURL)</li> <li>Resource estimation</li> <li>Vertical vs. horizontal scaling</li> <li>Checklist:</li> <li> Design a URL shortener service</li> <li> Design a notification system</li> <li> Implement a rate limiter</li> <li> Map out data flow diagrams for existing services</li> </ul>"},{"location":"topics/System-Design/#level-2-architecture-patterns-styles","title":"Level 2: Architecture Patterns &amp; Styles","text":"<ul> <li>Competencies:</li> <li>Microservices vs. SOA</li> <li>Layered architecture</li> <li>Event-driven architecture</li> <li>Hexagonal/clean/onion architectures</li> <li>BFF pattern</li> <li>CQRS basics</li> <li>Shared-nothing architecture</li> <li>Key Tools &amp; Practices:</li> <li>API gateways</li> <li>Diagram tools (C4 model)</li> <li>Event modeling</li> <li>Contract testing</li> <li>API versioning strategies</li> <li>Interface segregation</li> <li>Bounded contexts</li> <li>Checklist:</li> <li> Design a system using hexagonal architecture</li> <li> Implement a BFF for mobile and web clients</li> <li> Create an event-driven workflow</li> <li> Redesign a monolith toward service boundaries</li> </ul>"},{"location":"topics/System-Design/#level-3-distributed-systems","title":"Level 3: Distributed Systems","text":"<ul> <li>Competencies:</li> <li>Distributed transactions</li> <li>CQRS &amp; Event Sourcing</li> <li>Saga pattern</li> <li>Advanced message processing</li> <li>Consistent hashing</li> <li>Distributed caching</li> <li>Idempotency</li> <li>Key Tools &amp; Practices:</li> <li>Kafka for event streaming</li> <li>Redis/Memcached for distributed caching</li> <li>Distributed tracing (Jaeger, Zipkin)</li> <li>Optimistic concurrency control</li> <li>Backward/forward compatibility</li> <li>Data partitioning strategies</li> <li>Checklist:</li> <li> Design a payment system with Saga pattern</li> <li> Implement event sourcing for auditing</li> <li> Design a distributed file storage system</li> <li> Create a real-time analytics pipeline</li> </ul>"},{"location":"topics/System-Design/#level-4-large-scale-system-design","title":"Level 4: Large-Scale System Design","text":"<ul> <li>Competencies:</li> <li>Sharding strategies</li> <li>Replication patterns</li> <li>Content delivery</li> <li>Geospatial systems</li> <li>Rate limiting at scale</li> <li>Search architecture</li> <li>Streaming</li> <li>Key Tools &amp; Practices:</li> <li>Database sharding techniques</li> <li>CDN optimization</li> <li>Vector/similarity search</li> <li>Bloom filters</li> <li>Geospatial indexes</li> <li>Adaptive throttling</li> <li>Distributed consensus (Raft, Paxos)</li> <li>Checklist:</li> <li> Design a social media feed system</li> <li> Create a recommendation engine</li> <li> Design a large-scale chat application</li> <li> Implement a distributed search engine</li> </ul>"},{"location":"topics/System-Design/#level-5-enterprise-architecture","title":"Level 5: Enterprise Architecture","text":"<ul> <li>Competencies:</li> <li>Multi-region architectures</li> <li>Global data consistency</li> <li>Cross-region traffic</li> <li>Disaster recovery</li> <li>Custom distributed algorithms</li> <li>Platform design</li> <li>Migration strategies</li> <li>Key Tools &amp; Practices:</li> <li>Multi-region database solutions</li> <li>Global load balancing</li> <li>Chaos engineering</li> <li>Site reliability engineering</li> <li>Cost optimization</li> <li>Data sovereignty patterns</li> <li>Service mesh at scale</li> <li>Checklist:</li> <li> Design a global e-commerce platform</li> <li> Implement multi-region active-active architecture</li> <li> Create an internal service deployment platform</li> <li> Design zero-downtime system migration</li> </ul>"},{"location":"topics/System-Design/#resources","title":"Resources","text":"<ul> <li>System Design Primer (GitHub)</li> <li>Designing Data-Intensive Applications by Martin Kleppmann</li> <li>Awesome Scalability</li> </ul>"},{"location":"topics/System-Design/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: System Design Fundamentals (18-10-2025) <p>Status: Completed Focus: Architecture patterns, API design, caching, database selection, scalability Evidence: - Smart Deploy Monitor System Architecture - Multi-Database Architecture (Completed 18-10-2025): PostgreSQL, Redis, Elasticsearch, Qdrant integration - RESTful API Design (Completed 18-10-2025): OpenAPI/Swagger documentation with proper HTTP methods - Caching Strategy (Completed 18-10-2025): Redis TTL-based caching for performance optimization - Microservices Patterns (Completed 18-10-2025): Service layer architecture with dependency injection</p> <p>Comprehensive Implementation Evidence:</p> Step 1: Client-Server Architecture Implementation <p>HealthController Implementation: - GitHub Link: HealthController.java <pre><code>@RestController\n@RequestMapping(\"/api/health\")\npublic class HealthController {\n    @GetMapping(\"/ping\")\n    public ResponseEntity&lt;Map&lt;String, String&gt;&gt; ping() {\n        // Basic health check for load balancers\n    }\n\n    @GetMapping(\"/detailed\")\n    public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; detailedHealth() {\n        // Comprehensive health information\n    }\n}\n</code></pre></p> <p>ClientConfig Implementation: - GitHub Link: ClientConfig.java <pre><code>@Configuration\npublic class ClientConfig {\n    @Bean(\"clientRestTemplate\")\n    public RestTemplate clientRestTemplate() {\n        // HTTP client with timeout configuration\n        factory.setConnectTimeout(5000);\n        factory.setReadTimeout(10000);\n    }\n}\n</code></pre></p> Step 2: Monolith vs Microservices Implementation <p>UserDomainService - Business Logic Encapsulation: - GitHub Link: UserDomainService.java <pre><code>@Service\n@Transactional\npublic class UserDomainService {\n    public Optional&lt;User&gt; findUserById(UUID id) {\n        return userRepository.findById(id);\n    }\n\n    public Optional&lt;User&gt; performComplexUserOperation(UUID userId, boolean newStatus) {\n        // Complex business logic with inter-service communication\n    }\n}\n</code></pre></p> <p>ApiGatewayController - Centralized Routing: - GitHub Link: ApiGatewayController.java <pre><code>@RestController\n@RequestMapping(\"/api/gateway\")\npublic class ApiGatewayController {\n    @GetMapping(\"/users\")\n    public ResponseEntity&lt;List&lt;User&gt;&gt; getAllUsers() {\n        // Route to UserDomainService\n    }\n\n    @PostMapping(\"/notifications/email\")\n    public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; sendEmail(@RequestBody Map&lt;String, String&gt; request) {\n        // Route to NotificationDomainService\n    }\n}\n</code></pre></p> <p>NotificationDomainService - Domain Boundaries: - GitHub Link: NotificationDomainService.java</p> Step 3: Basic API Design Patterns Implementation <p>ApiResponse - Standardized Response Format: - GitHub Link: ApiResponse.java <pre><code>@JsonInclude(JsonInclude.Include.NON_NULL)\npublic class ApiResponse&lt;T&gt; {\n    private boolean success;\n    private String message;\n    private T data;\n    private String error;\n\n    public static &lt;T&gt; ApiResponse&lt;T&gt; success(T data) {\n        return new ApiResponse&lt;&gt;(true, \"Success\", data);\n    }\n}\n</code></pre></p> <p>ApiDesignController - RESTful Endpoints: - GitHub Link: ApiDesignController.java <pre><code>@RestController\n@RequestMapping(\"/api/design\")\npublic class ApiDesignController {\n    @GetMapping(\"/info\")\n    public ResponseEntity&lt;ApiResponse&lt;Map&lt;String, Object&gt;&gt;&gt; getInfo() {\n        // GET endpoint with proper response format\n    }\n\n    @PostMapping(\"/contact\")\n    public ResponseEntity&lt;ApiResponse&lt;String&gt;&gt; sendContact(@Valid @RequestBody ContactRequest request) {\n        // POST endpoint with validation\n    }\n}\n</code></pre></p> <p>Testing Evidence:</p> Health Check Endpoints Testing <p>Basic Health Check Response: <pre><code>{\n  \"service\": \"smart-deploy-monitor\",\n  \"status\": \"UP\",\n  \"timestamp\": \"1761348363913\"\n}\n</code></pre></p> <p>Detailed Health Check Response: <pre><code>{\n  \"service\": \"smart-deploy-monitor\",\n  \"version\": \"1.0.0\",\n  \"status\": \"UP\",\n  \"timestamp\": 1761348368794,\n  \"uptime\": 1761348368794\n}\n</code></pre></p> API Gateway Testing <p>User Management via Gateway: <pre><code>{\n  \"success\": true,\n  \"service\": \"User Domain Service\",\n  \"count\": 0,\n  \"message\": \"Users retrieved successfully via gateway\",\n  \"users\": []\n}\n</code></pre></p> <p>Email Notification via Gateway: <pre><code>{\n  \"success\": true,\n  \"service\": \"Notification Domain Service\",\n  \"message\": \"Email notification sent successfully via gateway\"\n}\n</code></pre></p> API Design Patterns Testing <p>GET Endpoint Response: <pre><code>{\n  \"success\": true,\n  \"message\": \"API information retrieved\",\n  \"data\": {\n    \"name\": \"Smart Deploy Monitor API\",\n    \"version\": \"1.0.0\",\n    \"status\": \"operational\"\n  }\n}\n</code></pre></p> <p>POST Endpoint with Validation: <pre><code>{\n  \"success\": true,\n  \"message\": \"Contact message received\",\n  \"data\": \"Message from Ali (ali@example.com): This is a test message for API design\"\n}\n</code></pre></p> <p>Error Response Format: <pre><code>{\n  \"success\": false,\n  \"error\": \"This is a demonstration of error handling\"\n}\n</code></pre></p> <p>Comprehensive Test Results: - \u2705 Health Endpoints: All health checks responding correctly (UP, READY, ALIVE status) - \u2705 API Gateway: Successfully routing requests to domain services - \u2705 Notification Services: Email and SMS notifications working with validation - \u2705 API Design: All HTTP methods (GET, POST, PUT, DELETE) working with proper status codes - \u2705 Request Validation: Comprehensive validation with detailed error messages - \u2705 Error Handling: Consistent error response format across all endpoints - \u2705 Domain Services: Clear business logic encapsulation and service boundaries - \u2705 Inter-Service Communication: Simulated notification processing working correctly</p> <p>System Architecture Evidence:</p> Smart Deploy Monitor System Architecture <p>Multi-Layer Architecture: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Client Layer                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502  \u2502   Web UI    \u2502  \u2502  Mobile App  \u2502  \u2502   API Client\u2502        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  API Gateway Layer                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502           ApiGatewayController                          \u2502\u2502\n\u2502  \u2502  \u2022 Centralized Routing                                 \u2502\u2502\n\u2502  \u2502  \u2022 Service Orchestration                               \u2502\u2502\n\u2502  \u2502  \u2022 Request/Response Transformation                     \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 Domain Services Layer                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502 UserDomainService\u2502  \u2502NotificationDomain\u2502  \u2502 HealthController\u2502\u2502\n\u2502  \u2502 \u2022 User Management\u2502  \u2502 \u2022 Email/SMS/Push\u2502  \u2502 \u2022 Health Checks\u2502\u2502\n\u2502  \u2502 \u2022 Business Logic\u2502  \u2502 \u2022 Notifications \u2502  \u2502 \u2022 System Status\u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Data Access Layer                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502   PostgreSQL    \u2502  \u2502     Redis       \u2502  \u2502  Elasticsearch  \u2502\u2502\n\u2502  \u2502 \u2022 User Data     \u2502  \u2502 \u2022 Caching       \u2502  \u2502 \u2022 Search/Filter \u2502\u2502\n\u2502  \u2502 \u2022 Transactions \u2502  \u2502 \u2022 Sessions      \u2502  \u2502 \u2022 Analytics     \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Deployment Evidence:</p> Docker Compose Multi-Service Architecture <p>Services Configuration: - GitHub Link: docker-compose.yml <pre><code>services:\n  smart-deploy-monitor:\n    build: .\n    ports:\n      - \"8080:8080\"\n    depends_on:\n      - postgres\n      - redis\n      - elasticsearch\n      - qdrant\n      - keycloak\n\n  postgres:\n    image: postgres:15\n    environment:\n      POSTGRES_DB: smart_deploy_monitor\n      POSTGRES_USER: admin\n      POSTGRES_PASSWORD: password\n\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6379:6379\"\n\n  elasticsearch:\n    image: elasticsearch:8.11.0\n    environment:\n      - discovery.type=single-node\n      - xpack.security.enabled=false\n</code></pre></p> <p>Performance &amp; Monitoring Evidence:</p> System Monitoring &amp; Observability <p>Health Check Endpoints: - <code>/api/health/ping</code> - Basic health check (UP/DOWN) - <code>/api/health/detailed</code> - Comprehensive system information - <code>/api/health/ready</code> - Readiness check for traffic acceptance - <code>/api/health/live</code> - Liveness check for service monitoring</p> <p>Monitoring Metrics: - System uptime tracking - Memory usage monitoring - CPU core utilization - Active connections count - Request processing metrics</p> <p>Logging Evidence: <pre><code>2025-10-25 03:24:02 [scheduling-1] INFO  c.u.s.service.MonitoringService - \nSystem Status - Uptime: 0s, Memory: 127.95/178.00MB, CPU Cores: 8, \nRequests: 0, Connections: 23\n</code></pre></p> <p>Security Implementation Evidence:</p> Security Configuration &amp; Authentication <p>Spring Security Configuration: - GitHub Link: SecurityConfig.java <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig {\n    @Bean\n    public SecurityFilterChain filterChain(HttpSecurity http) {\n        return http\n            .csrf(AbstractHttpConfigurer::disable)\n            .authorizeHttpRequests(auth -&gt; auth\n                .requestMatchers(\"/api/health/**\").permitAll()\n                .requestMatchers(\"/api/design/**\").permitAll()\n                .requestMatchers(\"/api/gateway/**\").permitAll()\n                .anyRequest().authenticated()\n            )\n            .build();\n    }\n}\n</code></pre></p> <p>JWT Authentication: - GitHub Link: AuthService.java - Token-based authentication implemented - Access and refresh token support - Secure password hashing with BCrypt - Role-based access control (RBAC)</p> <p>What I Learned: - Architecture Patterns: Layered architecture with Controller-Service-Repository pattern - API Design: RESTful principles with proper HTTP methods and status codes - Database Selection: Right database for right use case (PostgreSQL, Redis, Elasticsearch, Qdrant) - Caching Strategy: TTL-based caching with Redis for performance optimization - Scalability Patterns: Horizontal scaling considerations and load balancing - System Integration: Multi-service architecture with proper separation of concerns</p> <p>Applied Knowledge: - Designed multi-database architecture for different data types and access patterns - Implemented RESTful API with OpenAPI documentation and validation - Applied caching strategies for frequently accessed data - Used dependency injection for loose coupling and testability - Implemented proper error handling and response formatting - Applied microservices patterns within a monolithic application</p> <p>Architecture Examples: <pre><code>// Layered Architecture Pattern\n@RestController\npublic class UserController {\n    @Autowired\n    private UserService userService;\n\n    @PostMapping(\"/api/users\")\n    public ResponseEntity&lt;UserResponse&gt; createUser(@Valid @RequestBody UserDTO userDTO) {\n        return ResponseEntity.ok(userService.createUser(userDTO));\n    }\n}\n\n@Service\npublic class UserService {\n    @Autowired\n    private UserRepository userRepository;\n\n    @Autowired\n    private RedisService redisService;\n\n    public UserResponse createUser(UserDTO userDTO) {\n        // Business logic with caching\n        User user = userRepository.save(convertToEntity(userDTO));\n        redisService.setWithTTL(\"user:\" + user.getId(), user, 3600);\n        return convertToResponse(user);\n    }\n}\n</code></pre></p> <p>System Design Principles Applied: - Single Responsibility: Each service handles one concern - Dependency Inversion: Depend on abstractions, not concretions - Open/Closed: Open for extension, closed for modification - Interface Segregation: Small, focused interfaces - DRY Principle: Don't repeat yourself</p> <p>Resources Used: - Spring Boot architecture patterns and best practices - RESTful API design principles - Database selection criteria and patterns - Caching strategies and performance optimization - System design principles and scalability patterns</p> <p>Key Achievement: Successfully designed and implemented a scalable system architecture with multi-database integration, RESTful APIs, caching strategies, and proper separation of concerns, demonstrating professional system design skills.</p> Level 2: Design Patterns <p>Status: Planned Focus: Architecture patterns, CQRS, BFF, shared-nothing</p> Level 3: Distributed Systems <p>Status: Planned Focus: Distributed systems, saga, event sourcing</p> Level 4: Advanced Systems <p>Status: Planned Focus: Sharding, geospatial, streaming systems</p> Level 5: Global Scale <p>Status: Planned Focus: Multi-region, global consistency, custom algorithms</p>"},{"location":"topics/System-Design/#personal-notes","title":"Personal Notes","text":"Step 1: Client-Server Architecture (Completed 18-10-2025) <p>What I Implemented: - HealthController: Created comprehensive health check endpoints demonstrating client-server communication patterns   - <code>/api/health/ping</code> - Basic health check for load balancers   - <code>/api/health/detailed</code> - Comprehensive health information   - <code>/api/health/ready</code> - Readiness check for traffic acceptance   - <code>/api/health/live</code> - Liveness check for service monitoring - ClientConfig: Implemented HTTP client configuration with proper timeout management   - Connection timeout configuration (5 seconds)   - Read timeout configuration (10 seconds)   - Error handling for better client-server communication   - RestTemplate bean configuration for dependency injection</p> <p>What I Learned: - Health Check Patterns: Different types of health checks serve different purposes in client-server architecture - Timeout Management: Proper timeout configuration prevents hanging connections and improves reliability - Error Handling: Implementing proper error handling in HTTP clients improves system resilience - RESTful Design: Health endpoints follow RESTful principles and provide clear client-server contracts</p> <p>Applied Knowledge: - Implemented health check endpoints that clients can use for monitoring and load balancing - Configured HTTP clients with appropriate timeouts for production environments - Applied dependency injection patterns for client configuration - Created clear API contracts for client-server communication</p> <p>Key Achievement: Successfully implemented client-server architecture patterns with comprehensive health checks and proper HTTP client configuration, demonstrating understanding of client-server communication patterns and system monitoring requirements.</p> Step 2: Monolith vs Microservices (Completed 18-10-2025) <p>What I Implemented: - UserDomainService: Created comprehensive domain service for user management   - Business logic encapsulation for user creation, updates, and validation   - Domain boundaries that could be extracted into a microservice   - Business validation and error handling - NotificationDomainService: Implemented notification domain service   - Email, SMS, and push notification business logic   - Domain encapsulation for notification processing   - Inter-service communication simulation - ApiGatewayController: Created centralized routing controller   - Centralized entry point for all domain services   - API Gateway pattern implementation   - Service orchestration and routing</p> <p>What I Learned: - Domain Boundaries: Clear separation of business logic into domain services - Service Encapsulation: Each domain service encapsulates its own business logic - API Gateway Pattern: Centralized routing and service orchestration - Monolith Evolution: How to structure a monolith for future microservices extraction</p> <p>Applied Knowledge: - Implemented domain services with clear business boundaries - Created API Gateway pattern for centralized routing - Applied domain-driven design principles - Demonstrated how monolith can evolve toward microservices</p> <p>Key Achievement: Successfully implemented monolith vs microservices patterns with domain services, API Gateway routing, and clear service boundaries, demonstrating understanding of how to structure applications for future microservices evolution.</p> Step 3: Basic API Design Patterns (Completed 18-10-2025) <p>What I Implemented: - ApiResponse: Created standardized response format for consistent API responses   - Success and error response handling   - Generic type support for different data types   - Consistent JSON structure across all endpoints - ApiDesignController: Implemented comprehensive API design patterns   - GET /api/design/info: API information endpoint with proper response format   - POST /api/design/contact: Contact form with request validation   - PUT /api/design/settings/{id}: Settings update with proper HTTP status codes   - DELETE /api/design/data/{id}: Data deletion with confirmation   - Error handling demonstration with proper error responses - Request Validation: Implemented comprehensive input validation   - @Valid, @NotBlank, @Email, @Size annotations   - Detailed error messages for validation failures   - Proper HTTP status codes for different error types</p> <p>What I Learned: - API Design Principles: Consistent response format and proper HTTP status codes - Request Validation: Input validation with detailed error messages - RESTful Design: Proper use of HTTP methods (GET, POST, PUT, DELETE) - Error Handling: User-friendly error responses and proper status codes - Response Formatting: Standardized API response structure</p> <p>Applied Knowledge: - Implemented consistent API response format across all endpoints - Applied proper HTTP status codes (200, 201, 400) for different scenarios - Created comprehensive request validation with detailed error messages - Designed RESTful endpoints following API design best practices - Implemented proper error handling with user-friendly messages</p> <p>Key Achievement: Successfully implemented basic API design patterns with consistent response format, proper HTTP status codes, comprehensive request validation, and RESTful endpoint design, demonstrating understanding of essential API design principles and best practices.</p>"},{"location":"topics/TEMPLATE/","title":"[Topic Name]","text":"<p>Goal: [Brief description of the learning goal]</p> <p>Current Level: Level 1</p>"},{"location":"topics/TEMPLATE/#level-1-level-1-name","title":"Level 1: [Level 1 Name]","text":"<ul> <li>Competencies: [List key competencies]</li> <li>Tools: [List tools and technologies]</li> <li>Checklist:</li> <li> [Task 1]</li> <li> [Task 2]</li> <li> [Task 3]</li> </ul>"},{"location":"topics/TEMPLATE/#level-2-level-2-name","title":"Level 2: [Level 2 Name]","text":"<ul> <li>Competencies: [List key competencies]</li> <li>Tools: [List tools and technologies]</li> <li>Checklist:</li> <li> [Task 1]</li> <li> [Task 2]</li> <li> [Task 3]</li> </ul>"},{"location":"topics/TEMPLATE/#level-3-level-3-name","title":"Level 3: [Level 3 Name]","text":"<ul> <li>Competencies: [List key competencies]</li> <li>Tools: [List tools and technologies]</li> <li>Checklist:</li> <li> [Task 1]</li> <li> [Task 2]</li> <li> [Task 3]</li> </ul>"},{"location":"topics/TEMPLATE/#level-4-level-4-name","title":"Level 4: [Level 4 Name]","text":"<ul> <li>Competencies: [List key competencies]</li> <li>Tools: [List tools and technologies]</li> <li>Checklist:</li> <li> [Task 1]</li> <li> [Task 2]</li> <li> [Task 3]</li> </ul>"},{"location":"topics/TEMPLATE/#level-5-level-5-name","title":"Level 5: [Level 5 Name]","text":"<ul> <li>Competencies: [List key competencies]</li> <li>Tools: [List tools and technologies]</li> <li>Checklist:</li> <li> [Task 1]</li> <li> [Task 2]</li> <li> [Task 3]</li> </ul>"},{"location":"topics/TEMPLATE/#resources","title":"Resources","text":"<ul> <li>Resource 1</li> <li>Resource 2</li> <li>Resource 3</li> <li>ChatGPT for code examples and troubleshooting</li> </ul>"},{"location":"topics/TEMPLATE/#progress","title":"Progress","text":"Level 1: [Level 1 Name] <p>Status: Completed Focus: [Key focus areas] Tools Used: [Tools used] Evidence: - [Link to project/repository] - Achievement 1 (Completed [Date]): [Description] - Achievement 2 (Completed [Date]): [Description]</p> <p>What I Learned: - [Learning point 1] - [Learning point 2] - [Learning point 3]</p> <p>Resources Used: - [Resource used] - [Resource used] - [Resource used]</p> <p>Applied Knowledge: - [How knowledge was applied] - [How knowledge was applied] - [How knowledge was applied]</p> <p>All Level 1 tasks completed!</p> Level 2: [Level 2 Name] <p>Status: Planned Focus: [Key focus areas]</p> Level 3: [Level 3 Name] <p>Status: Planned Focus: [Key focus areas]</p> Level 4: [Level 4 Name] <p>Status: Planned Focus: [Key focus areas]</p> Level 5: [Level 5 Name] <p>Status: Planned Focus: [Key focus areas]</p>"},{"location":"topics/TEMPLATE/#evidence","title":"Evidence","text":"Level 1 Evidence <p>Repository: [Link to project/repository] Demonstrations: - [Demonstration 1] - [Demonstration 2] - [Demonstration 3]</p> <p>Key Features: - \u2705 [Feature 1] - \u2705 [Feature 2] - \u2705 [Feature 3]</p> <p>Testing Results: - \u2705 [Test result 1] - \u2705 [Test result 2] - \u2705 [Test result 3]</p>"},{"location":"topics/TEMPLATE/#personal-notes","title":"Personal Notes","text":"Note #1: [Implementation Name] ([Date]) <p>To achieve Level 1: [Level 1 Name], I implemented:</p> <p>1. [Implementation Point 1] <pre><code>// Code example\n</code></pre></p> <p>2. [Implementation Point 2] <pre><code>// Code example\n</code></pre></p> <p>3. [Implementation Point 3] <pre><code>// Code example\n</code></pre></p> <p>Key Learning: [Key learning or insight from the implementation]</p>"},{"location":"topics/Testing/","title":"Testing","text":"<p>Goal: Confidently test and validate software.</p> <p>Current Level: Level 1</p>"},{"location":"topics/Testing/#level-1-basic-testing","title":"Level 1: Basic Testing","text":"<ul> <li>Competencies: Write unit tests for Spring Boot applications, test REST controllers and services, use JUnit 5 and Mockito, apply arrange-act-assert pattern, measure code coverage</li> <li>Tools: JUnit 5, Mockito, Spring Boot Test, Maven Surefire, JaCoCo</li> <li>Checklist:</li> <li> Write unit tests for service layer methods</li> <li> Test REST controller endpoints with MockMvc</li> <li> Use mocks for dependencies and external services</li> <li> Configure and review code coverage reports</li> </ul>"},{"location":"topics/Testing/#level-2-integration-testing","title":"Level 2: Integration Testing","text":"<ul> <li>Competencies: Develop integration tests for Spring Boot applications, test database interactions, use @SpringBootTest, test with real database connections</li> <li>Tools: @SpringBootTest, @DataJpaTest, @WebMvcTest, TestContainers, H2 Database</li> <li>Checklist:</li> <li> Write integration tests for REST API endpoints with real database</li> <li> Test database operations with @DataJpaTest</li> <li> Use TestContainers for database integration tests</li> <li> Integrate tests into CI pipeline with automated coverage reporting</li> </ul>"},{"location":"topics/Testing/#level-3-advanced-testing","title":"Level 3: Advanced Testing","text":"<ul> <li>Competencies: Implement table-driven tests for complex logic and concurrency, write benchmarks for backend performance, simulate load and detect race conditions, test middleware and error handling.</li> <li>Tools: <code>go test -race</code>, Go benchmarking, advanced Testify, GoMock or similar</li> <li>Checklist:</li> <li> Develop benchmarks for high-traffic API endpoints</li> <li> Write tests that simulate concurrent requests and identify race conditions</li> <li> Test custom middleware and simulate error scenarios</li> </ul>"},{"location":"topics/Testing/#level-4-expert-testing","title":"Level 4: Expert Testing","text":"<ul> <li>Competencies: Design end-to-end tests for distributed systems, use Docker-based test environments, verify async processing and inter-service communication.</li> <li>Tools: Docker, Docker Compose, testcontainers-go, integration frameworks, CI with multi-container support</li> <li>Checklist:</li> <li> Build an end-to-end test suite using Docker</li> <li> Simulate async processing and verify results</li> <li> Integrate comprehensive E2E tests within CI/CD</li> </ul>"},{"location":"topics/Testing/#level-5-master-testing","title":"Level 5: Master Testing","text":"<ul> <li>Competencies: Architect load and performance tests for Golang backends, integrate security/static analysis, apply chaos testing to assess resilience, mentor others on scalable testing.</li> <li>Tools: Go benchmarks, Vegeta, chaos tools, <code>golangci-lint</code>, CI/CD with performance dashboards</li> <li>Checklist:</li> <li> Develop load testing for real-world stress scenarios</li> <li> Incorporate automated security and static analysis into CI</li> <li> Lead testing optimization and mentoring initiatives</li> </ul>"},{"location":"topics/Testing/#resources","title":"Resources","text":"<ul> <li>Testing Trophy by Kent C. Dodds</li> <li>OWASP Testing Guide</li> <li>Awesome Testing</li> </ul>"},{"location":"topics/Testing/#progress-evidence","title":"Progress &amp; Evidence","text":"Level 1: Basic Testing (18-10-2025) <p>Status: Completed Focus: Unit testing, REST controller testing, service layer testing, code coverage Evidence: - Smart Deploy Monitor Test Suite - Unit Tests (Completed 18-10-2025): Comprehensive unit tests for controllers and services - Integration Tests (Completed 18-10-2025): Database integration tests with @SpringBootTest - Code Coverage (Completed 18-10-2025): JaCoCo coverage reporting integrated with Maven</p> <p>What I Learned: - JUnit 5 Testing: Modern testing framework with annotations and assertions - Mockito Mocking: Mocking dependencies and external services for isolated testing - Spring Boot Test: @SpringBootTest, @WebMvcTest, @DataJpaTest for different test types - MockMvc Testing: Testing REST controllers with HTTP request simulation - Test Coverage: JaCoCo integration for code coverage measurement - Test Organization: Arrange-Act-Assert pattern and test structure best practices</p> <p>Applied Knowledge: - Created comprehensive unit tests for UserService and UserController - Implemented MockMvc tests for all REST endpoints - Used Mockito to mock database repositories and external services - Configured JaCoCo for code coverage reporting - Integrated testing into CI/CD pipeline with GitHub Actions - Applied testing best practices for maintainable test code</p> <p>Code Examples: <pre><code>@SpringBootTest\n@AutoConfigureMockMvc\nclass DemoControllerTest {\n    @Autowired\n    private MockMvc mockMvc;\n\n    @Test\n    void testHealthEndpoint() throws Exception {\n        mockMvc.perform(get(\"/health\"))\n            .andExpect(status().isOk())\n            .andExpect(content().string(\"Application is running!\"));\n    }\n}\n</code></pre></p> <p>Resources Used: - JUnit 5 documentation and best practices - Spring Boot Testing documentation - Mockito framework for mocking - JaCoCo for code coverage - Maven Surefire for test execution</p> <p>Key Achievement: Successfully implemented comprehensive testing suite for Spring Boot application with unit tests, integration tests, and code coverage reporting, demonstrating professional testing skills.</p> Level 2: Integration Testing <p>Status: Planned Focus: Integration tests, HTTP simulation, CI integration</p> Level 3: Advanced Testing <p>Status: Planned Focus: Complex tests, benchmarks, middleware testing</p> Level 4: End-to-End Testing <p>Status: Planned Focus: E2E tests, container-based integration</p> Level 5: Enterprise Testing <p>Status: Planned Focus: Performance, security, chaos testing</p>"},{"location":"topics/Testing/#personal-notes","title":"Personal Notes","text":""},{"location":"topics/Upskilling-Matrix/","title":"Upskilling Journey Matrix","text":"<p>This matrix outlines the progressive skill levels across key backend and DevOps topics.</p> Topic Level 1 Level 2 Level 3 Level 4 Level 5 Git &amp; GitHub Fundamentals: Init, Clone, Basic Commands, Branching Advanced Branching, Rebasing, Merge Strategies Recovery, Security, CI/CD, GitHub Actions GitOps, Enterprise Git Strategies, Large Codebases Deep Git Internals, Large-Scale GitOps, Custom Automation Project Management Task Breakdown, Basic Prioritization, Time Tracking Sprint Planning, Story Points, Task Complexity, Team Collaboration Risk Management, Dependency Handling, Backlog Grooming Cross-Team Collaboration, Release Planning, Scaling Agile Large-Scale Planning, Engineering Leadership, Metrics-Driven Decisions Communication &amp; Collaboration Basic Team Communication, Standups, Async Updates Writing Clear PRs, Giving &amp; Receiving Feedback, Meeting Etiquette Client &amp; Cross-Team Collaboration, Conflict Resolution Knowledge Sharing, Mentorship, Public Speaking, Documentation Mastery Leadership Communication, Technical Writing, Developer Advocacy Leadership To be added\u2026 Documentation To be added\u2026 Containers &amp; Orchestration Docker Basics: Images, Containers, Volumes Docker Compose, Networking, Storage, Registries Kubernetes Basics, Swarm, Helm, CI/CD Pipelines Kubernetes Advanced: Scaling, Security, Observability Enterprise Kubernetes: Multi-Cluster, Custom Operators Linux Linux CLI Basics, Filesystem Navigation, Permissions Package Managers, Shell Scripting, System Monitoring, WSL Process Management, Server Management, Bash Automation Virtualization, Containerization, Security Hardening Kernel Customization, Infra as Code, Large-Scale Automation CI/CD Basics of CI/CD, GitHub Actions, YAML Pipelines Automated Testing, Deployment Pipelines Secure CI/CD Pipelines, Terraform (Optional) Multi-Environment Pipelines, Self-Hosted Runners Enterprise CI/CD, Full Infra Automation Observability Observability Logging, Metrics, Application Monitoring Centralized Logging, ELK, Prometheus Full Observability Stack, OpenTelemetry, Alerting AI-Based Monitoring, Infra Health Automation Redundancy &amp; DR Basic Backup Automated Backups &amp; Monitoring HA (High Availability) DR Planning Self-Healing, Multi-Region Active-Active Networking OSI model, TCP/IP, Subnet, HTTP, ping, traceroute DNS, Load Balancing, VPN, Proxy SSL/TLS, API Gateways, SDN, VPC/Subnet K8s Network Models, Service Mesh, Zero Trust Multi-cloud, Custom Protocols, Global Traffic Mgmt Code + Design Patterns Backend Lang + Data Structures, Idiomatic Code Classic Patterns, Clean Code, Modularity Advanced Problem Solving, Leetcode Medium+ Code Quality Reviews, Long-Term Maintainability Org-wide Architecture &amp; Best Practices Databases SQL, Redis, Elasticsearch, Qdrant Fundamentals Schema Design, Indexing, Expiration Strategies CTEs, Triggers, Aggs, Streaming, Rate Limiting Read/Write Replication, Multi-layered Caching, TLS tuning Distributed DBs, Monitoring, Multimodal Search, Multi-Region System Design Monolith vs Microservices, Load Balancing, Caching Architecture Patterns, CQRS, BFF, Shared-Nothing Distributed Systems, Saga, Event Sourcing Sharding, Geospatial, Streaming Systems Multi-Region, Global Consistency, Custom Algorithms Security Basic Security Practices Secure Dev Practices App Layer Threat Modeling, Secure SDLC Continuous Security &amp; Monitoring Zero Trust, Offensive Readiness API HTTP Basics, REST API, Tools Versioning, Validation, Pagination GraphQL, gRPC, Protofiles Tokens, Gateways, RBAC, Rate Limits Federated APIs, Lifecycle Mgmt, Multi-Team Compatibility Auth &amp; Authorization Auth vs AuthZ, Cookies, Sessions, Hashing Session Mgmt, RBAC JWT, OAuth2, Scopes SSO, OAuth2, MFA, Protocols Passwordless, WebAuthn, Zero-Trust, Logging Testing Unit Testing, Table-Driven Tests, Coverage Integration Tests, HTTP Simulation, CI Complex Tests, Benchmarks, Middleware End-to-End Tests, Container-based Integration Performance, Security, Chaos Testing"}]}